{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import time\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT\n",
    "from vanilla_transformer import TransformerLM, TransformerConfig\n",
    "from retnet import RetNet, retnet_1_3b, RetNetConfig\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out' # ignored if init_from is not 'resume'\n",
    "start = \"\\nAs the man walked down the stairs, \" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 5 # number of samples to draw\n",
    "max_new_tokens = 1000 # number of tokens generated in each sample\n",
    "temperature = 1 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 50 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 10\n",
    "model_name = 'ckpt_r_2048.pt'\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "isRetnet = True\n",
    "isTransformer = False\n",
    "#exec(open('configurator.py').read()) # overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetNetConfig(block_size=2048, vocab_size=50304, n_layer=4, n_head=16, n_embd=256, dropout=0.0, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukev\\anaconda3\\envs\\thesis_clean\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "\n",
      "As the man walked down the stairs, owbrium off;\n",
      "Of all: yet?\n",
      "But by their female too much you are the day.\n",
      "BRO:\n",
      "I never be not I am this place and to the crown,\n",
      "Which thou did never speak.\n",
      "HENI'll play a prayer.\n",
      "My husband's a noble heart,\n",
      "Thanio,\n",
      "If you the law, by my breast, it is my good\n",
      "As, and what you are I should not to take.\n",
      "\n",
      "First Murderer:\n",
      "And, she with me not like a Montague!\n",
      "I say it\n",
      "\n",
      "COMINCE EDWARD:\n",
      "By the world,\n",
      "For your worship well in this?\n",
      "\n",
      "GLOUCESTER:\n",
      "'\n",
      "Amen, I will your voices'd my good Camillo.\n",
      "\n",
      "First Servingman:\n",
      "It was the city with me;\n",
      "But I, then, for you will make the queen,\n",
      "As bright track.\n",
      "O' faith hath a great affairs!\n",
      "LUCIO:\n",
      "A bachelor, the time of Gloucester and all thy hands.\n",
      "\n",
      "Clown:\n",
      "Marry, we have it had you both:\n",
      "Who, and therefore be great love from the world, and you to this!\n",
      "I may be no, my cousin that our mind:\n",
      "And in the Duke to thee;\n",
      "When I am not hear the king, though he hadst it!\n",
      "Their harness, and this way, good Camillo, who?\n",
      "\n",
      "\n",
      "TYBUCKINGHAM:\n",
      "In\n",
      "As it is, my master, as it?\n",
      "MENENVOLIO:\n",
      "I had won the people, he abroach,\n",
      "As we should I will make you think you.\n",
      "\n",
      "BRUTUS:\n",
      "I would say, my lord, my lord!\n",
      "My Lord:\n",
      "O-house, I love;\n",
      "A traitor: so, sir; let me a happy\n",
      "That you can the thing of this while thy land. But to be content.\n",
      "\n",
      "LUCIO:\n",
      "It's death is thy daughter!\n",
      "\n",
      "QUEENESCES:\n",
      "But, not now I can the people\n",
      "Or if some noble tribunes toad'd in peace,\n",
      "He hath not\n",
      "Were you have me,\n",
      "And from the crown, be that you.\n",
      "\n",
      "The king, then, we will be:\n",
      "Now Ph thy target in his noble\n",
      "What is it have his sin in the Duke of your head\n",
      "I thank you go not to see your name!\n",
      "\n",
      "In the matter and let them: but in the earth,\n",
      "To say you to tell;\n",
      "That our daughter; this: I have all is my mind;\n",
      "Forgive it out of her silver\n",
      "And yet to the queen.\n",
      "\n",
      "Messenger:\n",
      "The mayor, but to know you, when I would come, I am but yet\n",
      "Or with blood,\n",
      "That I have said, that they are in this offence:\n",
      "Nor he should have given him--though the gods\n",
      "For the common people.\n",
      "\n",
      "GREMIO:\n",
      "A most reverend fathers of us avoid, do you have power it that thy hands\n",
      "I have your eyes, and you'll send you\n",
      "As much but as we say\n",
      "To get your lords.\n",
      "\n",
      "\n",
      "KING HEN ELIZABETH:\n",
      "I do it is it exceeds, and wail to you,\n",
      "So easily.\n",
      "\n",
      "GLOUCESTER:\n",
      "That the day, if I mean of my father.\n",
      "\n",
      "\n",
      "POLIXENI know we hear the gods?\n",
      "\n",
      "MENENI know a prophet,\n",
      "For I beseech you\n",
      "Which never speak, my lord, the prince was you shall be so,\n",
      "That no, you can\n",
      "Thou wilt be so, she may be as thou hast of you so?\n",
      "\n",
      "ES:\n",
      "Good morrowsy no more, sir. As; but they were you all\n",
      "FIDI thank he do you think they do,\n",
      "As if I saw,\n",
      "But then, with me so\n",
      "And now that thou shalt have need. My clown\n",
      "\n",
      "JULI moral discipline her and to be, the law!\n",
      "\n",
      "LUCIO:\n",
      "My life of thy life, a thing,\n",
      "The law him, you see you shall\n",
      "And the Tower, that will be not a man come you,\n",
      "To hear my gracious prince, and all,\n",
      "\n",
      "As a gentle Warwick, with his friends for the matter.\n",
      "\n",
      "\n",
      "QUEENES:\n",
      "Peace, a sister. But my heart'st thou to a king\n",
      "A gloriousor, not dared:\n",
      "The time, is it, and I know you will be so.\n",
      "FRIARET: for all my mind, no less a thousand!\n",
      "\n",
      "DUCHESS OF\n",
      "---------------\n",
      "Elapsed time: 13.338027477264404\n",
      "\n",
      "As the man walked down the stairs, ine,\n",
      "LADY GREine eye we, thyself.\n",
      "First Servingman, to his brother's name:\n",
      "I'll take me\n",
      "That our streets; thou, he will be\n",
      "That duke, to do the king's death, my good\n",
      "With a king was he bites befal and more strength\n",
      "And then,\n",
      "On him for the Tower, that thou sham day:\n",
      "My lord, or nobleness was the devil,\n",
      "And leave.\n",
      "\n",
      "ROMEO:\n",
      "NIA:\n",
      "So early village have had I will keep him,\n",
      "We'll lay a king:\n",
      "A cherry you, and thou hadst thou lark.\n",
      "3 KING HENRY VI:\n",
      "My noble parent, and let the queen,\n",
      "Whose western\n",
      "HORTENSIO:\n",
      "If not to the time, we see a son. Give the world?\n",
      "\n",
      "Second Citizen:\n",
      "But the law it a lord mayor,\n",
      "And yet to your blood to be sworn you\n",
      "In his friends, 'twere,\n",
      "Who not, what it is here!\n",
      "As I make you, nor none?\n",
      "\n",
      "BRUTUS:\n",
      "I have\n",
      "Then with the world,--\n",
      "DUKE VINCENTIO:\n",
      "' faith, though they are in the world:\n",
      "I fear the city;\n",
      "With all our marriage and he that you may be no worse.\n",
      "\n",
      "\n",
      "MERCUTUS:\n",
      "KING EDWARD IV:\n",
      "No, good lord,\n",
      "To be my lord, our own notionest it? whence my master, with him;\n",
      "And let a subject.\n",
      "\n",
      "Messenger:\n",
      "What is the very pin'en blind, my lord!\n",
      "\n",
      "DUKE OF YORK:\n",
      "\n",
      "What you not speak, you talk of my meaning,\n",
      "Whose rocky, you may she were chosen the world of the\n",
      "By a royal selfsame\n",
      "And I say it hath done:\n",
      "I am too sore this prince, he dally: but I am\n",
      "I say that I not:\n",
      "The selfsame than a king.\n",
      "DUKE VINCENTIO:\n",
      "Nor what he, come hath got\n",
      "DUKE VINCENTIO:\n",
      "This is this earth I could tell that'st you be revenged.\n",
      "\n",
      "BRUTUS:\n",
      "This ague the gods, I may come hither the people. But.\n",
      "\n",
      "GLOUCESTER:\n",
      "Ay, madam: as you may blow\n",
      "I thought, they were flatter, and thy friend\n",
      "That is impossible for, good lady,\n",
      "Tush, then do what you well for thou hast of the king is an enemy.\n",
      "\n",
      "LADY ANNE:\n",
      "A Patric; his great\n",
      "Let them to go!\n",
      "\n",
      "LADYea,'.\n",
      "\n",
      "\n",
      "Y ANNE:\n",
      "And then?\n",
      "KING EDWARD IV:\n",
      "Then cannot choose:\n",
      "What, is very gross a little cost.\n",
      "\n",
      "First Servingman:\n",
      "No, that your houses, and make me his mind:\n",
      "Infer;\n",
      "But now and so I know this world. You have deserved;\n",
      "So that's to make for these shred the king is't.\n",
      "\n",
      "GLOUCESTER:\n",
      "I know the queen, then comes the sea, with\n",
      "It was a subject, I have done their heads: he hath left you both\n",
      "To this.\n",
      "\n",
      "LEONTES:\n",
      "Ay, he hath made o'clock,\n",
      "As to me to get thee to London, this morning is here;\n",
      "\n",
      "And will make I'll be it, let's.\n",
      "MAMILLI would tell thee.\n",
      "\n",
      "Second Murderer:\n",
      "Nurse:\n",
      "For then\n",
      "What was the Lord Marqu:\n",
      "He was, thou, when our general;\n",
      "And many days, and then.\n",
      "He is too:\n",
      "I was heard to\n",
      "\n",
      "CLARENCE:\n",
      "We follow the time to my lord, he shall you. Farewell,\n",
      "In signest:\n",
      "Where our way my lord? You,\n",
      "\n",
      "MIONE: thou art moved's love, and thou hast to London.\n",
      "\n",
      "GLOUCESTER:\n",
      "Good Edward, I'll not this day.\n",
      "\n",
      "COMINI will not.\n",
      "\n",
      "CORIUS:\n",
      "Thou art she?\n",
      "\n",
      "First Senator:\n",
      "POMASARENCE:\n",
      "What's eyes?\n",
      "SICINI am a traitor, good deed, and all this.\n",
      "And then, that I have had been, and most that you:\n",
      "Your highness of a wife with a father's son;\n",
      "The noble lord, but the common love.\n",
      "\n",
      "KING HENIUS:\n",
      "It had I will, with me,\n",
      "My Lord Fitz me, to come you have been.\n",
      "\n",
      "---------------\n",
      "Elapsed time: 11.506017446517944\n",
      "\n",
      "As the man walked down the stairs,  of the king,\n",
      "He and then to thee but on this:\n",
      "Then know my cousin,\n",
      "I do protest\n",
      "The king, but they were destined my life of the sun of war,\n",
      "But then in his grace,\n",
      "CAMILLO'ld bethink me\n",
      "Of their heads, the Duke of his great momentish'd to this be a gentleman before it,\n",
      "And then to heaven\n",
      "And see the city;\n",
      "And who abst he is most night of the best.\n",
      "First Citizen:\n",
      "He hath won as an orphan upon the king,\n",
      "To do thee, to have you were contrary. But\n",
      "Come at his father. But for ever you shall be too soon,\n",
      "Whensoever your own confession\n",
      "And why, thou have deserved nob which burns, for my part.\n",
      "Now shall she's thy hand:\n",
      "I'll warrant\n",
      "It was not a great one side factions talk.\n",
      "\n",
      "TRESS OF GAUNT:\n",
      "Your brotherly, when is so: O that's son,\n",
      "That I'll make a mile for Rome of you know.\n",
      "\n",
      "NORTHUMERLEONTES:\n",
      "Now Margaret, if I are well thou go.\n",
      "\n",
      "AUTOLYCUS:\n",
      "A crown. I pray'st a good and make me\n",
      "As thou hast my kingdom\n",
      "To say 'gainst thou hast sold'd the duke\n",
      "Their watches,\n",
      "The loss his father's good night, be thus have said;\n",
      "I am too much betteriles.\n",
      "\n",
      "JOHN OF GAUNTis, and my father, as\n",
      "When she\n",
      "Which have power, and they be well assured: and he hath offended thee Duke of their fortuneship,\n",
      "Of whom bemo oracle is a guest\n",
      "Like interrupted of any other.\n",
      "I know, he is your grace should undoanio?\n",
      "\n",
      "AUTOLINGHAM:\n",
      "We'll hear in the world!\n",
      "\n",
      "MARCIUS:\n",
      "I never lion. Nowinius have heard it'st of the Tower for his party atonement.\n",
      "\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "This is he shall we may not\n",
      "Will not: our lab with the earth to die?\n",
      "\n",
      "KING HENIET:\n",
      "Not it not that\n",
      "If what news and your lords,\n",
      "Of burning and he must be king, my brother!\n",
      "\n",
      "WARWICK:\n",
      "What, as a fool, and your honour,\n",
      "To meet my lord: but so long, I were thy country'st!\n",
      "\n",
      "DUKE OF GAUNTutio; I see the king.\n",
      "\n",
      "POLIXENI say.\n",
      "LUCIO:\n",
      "' the people and, though never\n",
      "You must inquire:\n",
      "And, do think for we'll give them do't\n",
      "In your father, be done the great great power; which.\n",
      "And if they follow thee by thy life?\n",
      "\n",
      "NORTHUMERLE:\n",
      "To get you would think your high; for that can no blood hath dev:\n",
      "To say there we heard thy son,\n",
      "For a man!\n",
      "Marry, and there's, this land of thy kindness a strange:\n",
      "And, this? O father,\n",
      "I do speak?\n",
      "MENENI will I say I thought.\n",
      "CUTUS:\n",
      "I have in good father:\n",
      "You have I will not.\n",
      "\n",
      "SICINI pray you would have heard a lady!\n",
      "\n",
      "SICINIUS:\n",
      "It is the princely.\n",
      "LORD WILLOUGHBY:\n",
      "My Lord Cobham, what says his wife, and as\n",
      "We will they are to be this same and\n",
      "To make me.\n",
      "\n",
      "TYRICHARD:\n",
      "It must grant you, if you, I had the wind?\n",
      "\n",
      "BRUTUS:\n",
      "Ay, then, what should have him with them;\n",
      "If I hope of a son, but the world.\n",
      "\n",
      "SICINI know, with a father:\n",
      "If I will marry be seen are gone,\n",
      "That he will. This:\n",
      "What is your majesty?\n",
      "\n",
      "\n",
      "BUCKINGHAM:\n",
      "O, what, do it were not at the dost:\n",
      "The day.\n",
      "\n",
      "QUEENI am not. My\n",
      "\n",
      "SICINA:\n",
      "You have your ways, I\n",
      "O blessed you are too!\n",
      "\n",
      "JULI shall keep you must go?\n",
      "With all the world were your grace!\n",
      "\n",
      "First Gentleman:\n",
      "BRUTUS:\n",
      "And therefore:\n",
      "To see her? What well.\n",
      "\n",
      "BRUTUS:\n",
      "Yes me, the day hath done.\n",
      "\n",
      "Provost:\n",
      "First Citizen:\n",
      "A:\n",
      "Your partner! I may be consul's wife.\n",
      "\n",
      "\n",
      "Second Servingman:\n",
      "What, then, and\n",
      "\n",
      "He is\n",
      "---------------\n",
      "Elapsed time: 11.39893651008606\n",
      "\n",
      "As the man walked down the stairs, lessious thee\n",
      "That you tell me to a doth is the\n",
      "That was slain is.\n",
      "FRIARET:\n",
      "The heavens have more of the people?\n",
      "\n",
      "BRUTue him:\n",
      "God keep her tender for thy news\n",
      "My lord, he has not of a Montagues:\n",
      "His glass to you with the queen\n",
      "anderers\n",
      "And\n",
      "To have been too:\n",
      "In the people, my uncle.\n",
      "\n",
      "QUE:\n",
      "We'll make your daughter the common blocks.\n",
      "\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "For I'll tell me in the day, and\n",
      "That shepherds of it, my lord?\n",
      "and a brace, and now well be it and\n",
      "you in a strange, or a great affairs, and I know not\n",
      "To give me with our state, as a lady's wife,\n",
      "And, though he shall be gone is grown to a thousand with\n",
      "Than thee, and,\n",
      "Have I make his head.\n",
      "And never hear these rebels wilt thou can me to the\n",
      "Your, which is at the king!\n",
      "As 'twere of\n",
      "Whose rocky, by the Duke of mine.\n",
      "That, for our heads.\n",
      "\n",
      "GLOUCESTER:\n",
      "What, he was that word, they not this day is no that?\n",
      "\n",
      "Second Watchmanoured, by their teeth;\n",
      "To whom me\n",
      "To save and not how I'll bear aught my father,\n",
      "His life oracle but for him for ever an ass he has,\n",
      "I am ready the king'st of the\n",
      "Injunction to keep my friends: what thou go to my life.\n",
      "\n",
      "PRINCE:\n",
      "Sir; I know the good man\n",
      "But to give a husband; but I'll be that I shall be the\n",
      "And, that hath reverend fathers, and the gates and wretch.\n",
      "\n",
      "Bury more than the very crown on my life, and that the world.\n",
      "\n",
      "CORI' hands the king'st thou art a little ungovern'd up thy revenge\n",
      "I must beauteous man\n",
      "Which's a traitor of me.\n",
      "\n",
      "Marry, sir, our country, then to be this;\n",
      "Thanio; if it is a slave a royal father'st-maidmen,\n",
      "For being warnuseft was the field.\n",
      "\n",
      "I dare is\n",
      "DUKE VINCENTIO:\n",
      "I warrant, he is done to speak.\n",
      "\n",
      "BRUTLAND:\n",
      "Is you\n",
      "Now all this noble uncle\n",
      "Not no less son by my good night.\n",
      "CES:\n",
      "And let him, no more\n",
      "My friends you, to the crown.\n",
      "KING EDWARD: but such a man that can alter the very nerves.\n",
      "\n",
      "Farewell, my lordship:\n",
      "And let's death; go:\n",
      "The king at Bristol:\n",
      "O noble lord.\n",
      "\n",
      "CUTUS:\n",
      "Now, then I see thee, good morrow.\n",
      "\n",
      "COMINI would my mother;\n",
      "It is but I canst thou dast with the king: but vain,\n",
      "Because the matter of thy life can:\n",
      "We do not. Your judgments. We in Rome,\n",
      "\n",
      "WARWICK:\n",
      "You fear it, then a subject no better and\n",
      "Your brother a most willingly a strange picklock,\n",
      "Till she should be put to a king of that he\n",
      "And I think her.\n",
      "\n",
      "KING RICHARD III:\n",
      "When my good to death.\n",
      "\n",
      "Farewell is the devil that hath he hath\n",
      "When now I will not to her brother's death,\n",
      "Than my daughter; but we have we were a feast; and I must use no matter?\n",
      "As thou weep.\n",
      "GLOUCESTER:\n",
      "Take it to win, that have a gentleman, good father the mayor in a man,\n",
      "Which makes him that can but one that did,\n",
      "If thou so.\n",
      "\n",
      "LORD FITZWICK:\n",
      "What, she sings'd, no matter to\n",
      "As if you were an end on the prince\n",
      "I hear.\n",
      "\n",
      "GLOUCESTER:\n",
      "Who I do you shall\n",
      "Nay, then I am content.\n",
      "\n",
      "PETER:\n",
      "That he did show you must be seen\n",
      "My brother'st the king:\n",
      "What say the hand! O;\n",
      "As passes him disparagement I must needs no quarrel;\n",
      "For even and I speak as our uncle\n",
      "The statue the ground and leave, but we fear of the Duke of thither not a man's king,\n",
      "And then?\n",
      "\n",
      "GLOUCESTER:\n",
      "And thus he not stay to\n",
      "What is you may call hers, with five hundred;\n",
      "And therefore to bear the thing and not\n",
      "That I know the Lord that your honour\n",
      "---------------\n",
      "Elapsed time: 11.370582342147827\n",
      "\n",
      "As the man walked down the stairs,  to deathland\n",
      "As the king of\n",
      "And therefore in good's heirs, that we may enter with ourself.\n",
      "\n",
      "Lest, which have more, thou shalt live\n",
      "If they had\n",
      "Of them with afoot from my master.\n",
      "That you are they give him\n",
      "KING EDWARD IV:\n",
      "O: but the heavens!\n",
      "Why, that you,--Oft and take my Lord:\n",
      "Than to be\n",
      "What comfortable to be good cousin the sun: for\n",
      "As Pri for the Lord and now,\n",
      "And I saw a lord?\n",
      "And that which's\n",
      "ANGELO:\n",
      "The law and I will you and I have a-maid\n",
      "Thou hast for her!\n",
      "\n",
      "\n",
      "Doth thy mind pres\n",
      "The nobility, what, and so do you?\n",
      "\n",
      "BRUTUS:\n",
      "I would say so\n",
      "For that you do\n",
      "\n",
      "SICINI know this cause to be not to have not know\n",
      "The noble tribune\n",
      "The very late with myself'd, when we were I do him\n",
      "That's death on; but she.\n",
      "\n",
      "NIA:\n",
      "My gracious lady's the news\n",
      "Than to do blasp!\n",
      "Sirs on the king.\n",
      "BRUTUS:\n",
      "SICINIUS:\n",
      "With all their gentle words!\n",
      "He is there to the cause:\n",
      "A:\n",
      "\n",
      "Where is no more successful, I say his partyor\n",
      "With fury: he helps they did contem, my life.\n",
      "\n",
      "TRANUS:\n",
      "To be, as they have power.\n",
      "\n",
      "KING EDWARD IV:\n",
      "I beseech your own desert, but now are thy hand of your name,\n",
      "In the morning op\n",
      "A place: he was at him with his body.\n",
      "'Thus have shaped, with child.\n",
      "\n",
      "ROMEO:\n",
      "Let me as much displeased, sir?\n",
      "But yet thou could he were they are I did thou may make him:\n",
      "Why is your voices,\n",
      "For I am a prince, and a mother is nothing but, and yet you;\n",
      "And all the queen is it.\n",
      "KING HENIOLANLEY:\n",
      "I am ang, with you know he be a kind,\n",
      "If you must be bold. But in this fair,\n",
      "Than history and to the queen'st thou\n",
      "Of my countrymen, you to my lord.\n",
      "\n",
      "DUKE OF YORK:\n",
      "We say 'twere\n",
      "\n",
      "CORIUS:\n",
      "Welcome, my lord, and yet.\n",
      "This is the queen, my liege, but,\n",
      "Upon agreement it be not you tell.\n",
      "\n",
      "First Conspirator: do\n",
      "A dog with you will be.\n",
      "\n",
      "LADY:\n",
      "What we are too hot:\n",
      "I know.\n",
      "\n",
      "HASTINGS:\n",
      "What shall be. Thou dece you the duke\n",
      "\n",
      "BRUTUS:\n",
      "Your way my sweet princely\n",
      "All is too hot my lord, I can learn, for these\n",
      "But to death to go;\n",
      "He came down of thy state.\n",
      "\n",
      "KING RICHARD II:\n",
      "IUS:\n",
      "I know you.\n",
      "\n",
      "First Keeper:\n",
      "Why, sir;\n",
      "Well made the earth, well;\n",
      "Is that you come to him.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Thou should you all the world to kill'd\n",
      "And yet thou so?\n",
      "PAULIET:\n",
      "I was an end on my husband by Saint Alban?\n",
      "\n",
      "SICINIET:\n",
      "Let me see.\n",
      "\n",
      "BRUTUS:\n",
      "Now I'll take one of thee:\n",
      "Your noble brother Clarence the first, if it;\n",
      "Thy words, that hath I'll watch, and\n",
      "From his body,\n",
      "With what we'll lay the end, as mine own eyes: be the people:\n",
      "My lord, as I not the people,\n",
      "Which I will to get you are well and the king;\n",
      "To me, a good.\n",
      "\n",
      "BRUTUS:\n",
      "We shall not yet\n",
      "As much, he promised me\n",
      "Which oft any undertaking the world?\n",
      "' the king canst not go? be the great momentdrumocks!\n",
      "\n",
      "LEONTES:\n",
      "I never orphans, my lord, as a Montague?\n",
      "A beggar:\n",
      "I will well.\n",
      "\n",
      "CLARENCE:\n",
      "Why should recount, you say he, be great,--a:\n",
      "And if he hath a great ones\n",
      "His land, and therefore a prin with me: let thy father's no less for the crown a man's\n",
      "And many days than her.\n",
      "\n",
      "BRUTUS:\n",
      "No, if I'll do suspect all good,\n",
      "But in the sun of heaven, good fellow, we should hear you are fled.\n",
      "My lord.\n",
      "\n",
      "HEN\n",
      "---------------\n",
      "Elapsed time: 11.057950973510742\n",
      "[13.338027477264404, 11.506017446517944, 11.39893651008606, 11.370582342147827, 11.057950973510742]\n",
      "11.734302949905395\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, model_name)\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    if isRetnet:\n",
    "        conf = RetNetConfig(**checkpoint['model_args'])\n",
    "        conf.n_embd = int(conf.n_embd)\n",
    "        print(conf)\n",
    "        model = RetNet(conf, \n",
    "        num_tokens=50304,\n",
    "        d_model=conf.n_embd,\n",
    "        nhead=conf.n_head,\n",
    "        num_layers=conf.n_layer,\n",
    "        dim_feedforward=conf.n_embd * 4)\n",
    "        device=device\n",
    "    elif isTransformer:\n",
    "        conf = TransformerConfig(**checkpoint['model_args'])\n",
    "        print(conf)\n",
    "        model = TransformerLM(conf, \n",
    "        num_tokens=50304,\n",
    "        d_model=conf.n_embd,\n",
    "        nhead=conf.n_head,\n",
    "        num_layers=conf.n_layer,\n",
    "        dim_feedforward=conf.n_embd * 4)\n",
    "        device=device\n",
    "    else:\n",
    "        gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "        model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "elif init_from.startswith('gpt2'):\n",
    "    # init from a given GPT-2 model\n",
    "    model = GPT.from_pretrained(init_from, dict(dropout=0.0))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if compile:\n",
    "    model = torch.compile(model) # requires PyTorch 2.0 (optional)\n",
    "\n",
    "# look for the meta pickle in case it is available in the dataset folder\n",
    "load_meta = False\n",
    "if init_from == 'resume' and 'config' in checkpoint and 'dataset' in checkpoint['config']: # older checkpoints might not have these...\n",
    "    meta_path = os.path.join('data', checkpoint['config']['dataset'], 'meta.pkl')\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "if load_meta:\n",
    "    print(f\"Loading meta from {meta_path}...\")\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    # TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "    stoi, itos = meta['stoi'], meta['itos']\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "else:\n",
    "    # ok let's assume gpt-2 encodings by default\n",
    "    print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "    decode = lambda l: enc.decode(l)\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "# run generation\n",
    "time_per_sample = []\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            start_time = time.time()\n",
    "            y = model.generate_parallel(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            #print(y)\n",
    "            print(decode(y[0].tolist()))\n",
    "            end_time = time.time()\n",
    "            print('---------------')\n",
    "            duration = end_time - start_time\n",
    "            print(f\"Elapsed time: {duration}\")\n",
    "            time_per_sample.append(duration)\n",
    "print(time_per_sample)\n",
    "print(sum(time_per_sample) / len(time_per_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import time\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT\n",
    "from vanilla_transformer import TransformerLM, TransformerConfig\n",
    "from retnet import RetNet, retnet_1_3b, RetNetConfig\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# support running without installing as a package\n",
    "#wd = Path(__file__).parent.parent.resolve()\n",
    "#sys.path.append(str(wd))\n",
    "\n",
    "from model import GPTConfig, GPT\n",
    "from quantization import GPTQQuantizer\n",
    "#from lit_llama.utils import EmptyInitOnDevice, llama_model_lookup\n",
    "\n",
    "\n",
    "model_name = 'ckpt_r_2048.pt'\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "isRetnet = True\n",
    "isTransformer = False\n",
    "out_dir = 'out'\n",
    "NR_SAMPLES = 128\n",
    "\n",
    "\n",
    "def get_sample_data():\n",
    "        # traindata = load_dataset(\n",
    "    #     \"allenai/c4\",\n",
    "    #     \"allenai--c4\",\n",
    "    #     data_files={\"train\": \"en/c4-train.00000-of-01024.json.gz\"},\n",
    "    #     split=\"train\",\n",
    "    # )\n",
    "    traindata = load_dataset(\n",
    "        \"wikitext\",\n",
    "        \"wikitext-2-v1\",\n",
    "        #data_files={\"train\": \"en/c4-train.00000-of-01024.json.gz\"},\n",
    "        split=\"train\",\n",
    "    )\n",
    "    # heuristic for the data size?\n",
    "    txt = \"\\n\".join(\n",
    "        traindata[i][\"text\"] for i in torch.randperm(len(traindata))[:5000].tolist()\n",
    "    )\n",
    "    return txt\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def llama_blockwise_quantization(\n",
    "    model, sample_inputs, working_device, *, bits=4, groupsize=-1\n",
    "):\n",
    "    \"\"\"\n",
    "    This is the classic post-training quantization of all linear layers.\n",
    "    We quantize in order, i.e. when observing the inputs, we use the outputs of the previously quantized layers rather\n",
    "    than doing them all at once.\n",
    "    \"\"\"\n",
    "    print(model)\n",
    "    print(model.config)\n",
    "\n",
    "    print(\"Getting inputs for first block\")\n",
    "    print(model.decoder)\n",
    "    model.embedding.to(working_device)\n",
    "    sample_inputs = sample_inputs.to(working_device)\n",
    "    inps = model.embedding(sample_inputs)\n",
    "    model.embedding.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    rope_cache = None\n",
    "    mask_cache = None\n",
    "\n",
    "    print(\"Starting to quantize blocks\")\n",
    "    outs = torch.zeros_like(inps)\n",
    "\n",
    "    # better than relying on enumeration? originally the code bundled\n",
    "    # the two mlp fc layers\n",
    "    # we could automate this with a lot of hooks and another iteration\n",
    "    submodules_to_process = [\n",
    "        \"retention.q_proj\",\n",
    "        \"retention.k_proj\",\n",
    "        \"retention.v_proj\",\n",
    "        \"retention.g_proj\",\n",
    "        \"linear1\",\n",
    "        \"linear2\",\n",
    "    ]\n",
    "\n",
    "    for i, block in enumerate(model.decoder.layers):\n",
    "        block.to(working_device)\n",
    "\n",
    "        for name in submodules_to_process:\n",
    "            print(i, name, end=\" \")\n",
    "            t0 = time.perf_counter()\n",
    "            print(\"collecting stats\", end=\" \")\n",
    "            sys.stdout.flush()\n",
    "            module = block.get_submodule(name)\n",
    "\n",
    "            gptq = GPTQQuantizer(\n",
    "                module,\n",
    "                bits=bits,\n",
    "                groupsize=groupsize,\n",
    "                actorder=(groupsize == -1),\n",
    "            )\n",
    "            handle = module.register_forward_hook(gptq.collect_input_stats)\n",
    "            for j in range(inps.size(0)):\n",
    "                outs[j : j + 1] = block(\n",
    "                    inps[j : j + 1],\n",
    "                )\n",
    "\n",
    "            handle.remove()\n",
    "\n",
    "            print(\"quantizing\", end=\" \")\n",
    "            sys.stdout.flush()\n",
    "            q_module, error = gptq.quantize()\n",
    "            # replace the linear module with the quantized module\n",
    "            if(len(name.rsplit(\".\", 1)) == 2):\n",
    "                pname, dname = name.rsplit(\".\", 1)\n",
    "                print(q_module, pname, dname)\n",
    "                setattr(block.get_submodule(pname), dname, q_module)\n",
    "            else:\n",
    "                print(q_module, name)\n",
    "                setattr(block, name, q_module)\n",
    "\n",
    "            # cleanup in an attempt to not run out of memory\n",
    "            del gptq\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            t1 = time.perf_counter()\n",
    "            print(f\"time {int(t1 - t0 + 0.5)}s quantization error {error:.1f}\")\n",
    "\n",
    "        for j in range(inps.size(0)):\n",
    "            outs[j : j + 1] = block(\n",
    "                inps[j : j + 1],\n",
    "            )\n",
    "\n",
    "        block.cpu()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # the outputs are the next block's inputs and we'll reuse the old inputs\n",
    "        inps, outs = outs, inps\n",
    "    # print(inps.size(0))\n",
    "    # for j in range(inps.size(0)):\n",
    "    #     model.decoder.layers[3].norm2.to(working_device)\n",
    "    #     outs[j : j + 1] = model.decoder.layers[3].norm2(inps[j : j + 1])\n",
    "    #     model.decoder.layers[3].norm2.to('cpu')\n",
    "    inps, outs = outs, inps\n",
    "    model.out.to(working_device)\n",
    "    gptq = GPTQQuantizer(\n",
    "        model.out,\n",
    "        bits=bits,\n",
    "        groupsize=groupsize,\n",
    "        actorder=(groupsize == -1),\n",
    "    )\n",
    "    handle = model.out.register_forward_hook(gptq.collect_input_stats)\n",
    "    for j in range(inps.size(0)):\n",
    "        model.out(inps[j : j + 1])\n",
    "    handle.remove()\n",
    "    q_module, error = gptq.quantize()\n",
    "    model.out = q_module\n",
    "    model.out.to(\"cpu\")\n",
    "    print(model)\n",
    "\n",
    "\n",
    "def quantizing(\n",
    "    *,\n",
    "    output_path: Optional[Path] = None,\n",
    "    n_samples: int = NR_SAMPLES,\n",
    "    dtype: str = \"float32\",\n",
    "    quantize: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"Generates text samples based on a pre-trained LLaMA model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: The checkpoint path to load.\n",
    "        output_path: Path to write the quantized model's state dict to.\n",
    "        tokenizer_path: The tokenizer path to load.\n",
    "        n_samples: Number of example inputs to use for statistics (default: 128)\n",
    "        dtype: The dtype to use to load the model.\n",
    "        quantize: Mode to quantize the model to:\n",
    "            ``\"gptq.int4\"``: GPTQ 4-bit mode.\n",
    "            Note that ``\"llm.int8\"```does not need a quantization step.\n",
    "    \"\"\"\n",
    "    device = \"cuda\"\n",
    "\n",
    "    dt = getattr(torch, dtype, None)\n",
    "    if not isinstance(dt, torch.dtype):\n",
    "        raise ValueError(f\"{dtype} is not a valid dtype.\")\n",
    "    dtype = dt\n",
    "\n",
    "    if quantize == \"gptq.int4\":\n",
    "        bits = 4\n",
    "    elif quantize == \"gptq.int8\":\n",
    "        bits = 8\n",
    "    else:\n",
    "        raise RuntimeError(f\"unknown/unsupported quantization mode {quantize}\")\n",
    "\n",
    "    # we avoid loading the entire model on the GPU and do this block by block\n",
    "    print(\"Loading model ...\", file=sys.stderr)\n",
    "    t0 = time.time()\n",
    "    ckpt_path = os.path.join(out_dir, model_name)\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    print(checkpoint['model_args'])\n",
    "    if isRetnet:\n",
    "        conf = RetNetConfig(**checkpoint['model_args'])\n",
    "        print(conf)\n",
    "        model = RetNet(conf, \n",
    "        num_tokens=50304,\n",
    "        d_model=conf.n_embd,\n",
    "        nhead=conf.n_head,\n",
    "        num_layers=conf.n_layer,\n",
    "        dim_feedforward=conf.n_embd * 4)\n",
    "        device=device\n",
    "    elif isTransformer:\n",
    "        conf = TransformerConfig(**checkpoint['model_args'])\n",
    "        print(conf)\n",
    "        model = TransformerLM(conf, \n",
    "        num_tokens=50304,\n",
    "        d_model=conf.n_embd,\n",
    "        nhead=conf.n_head,\n",
    "        num_layers=conf.n_layer,\n",
    "        dim_feedforward=conf.n_embd * 4)\n",
    "        device=device\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"Time to load model: {time.time() - t0:.02f} seconds.\", file=sys.stderr)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    def process(example):\n",
    "        ids = enc.encode_ordinary(example) # encode_ordinary ignores any special tokens\n",
    "        ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n",
    "        # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n",
    "        out = {'ids': ids, 'len': len(ids)}\n",
    "        return ids\n",
    "\n",
    "    # tokenize the dataset\n",
    "    text = get_sample_data()\n",
    "    encoded_text = torch.tensor(process(text))\n",
    "\n",
    "    # tokenizer = Tokenizer(tokenizer_path)\n",
    "\n",
    "    # test_string = get_sample_data()\n",
    "    # encoded_text = tokenizer.encode(\n",
    "    #     test_string,\n",
    "    #     bos=True,\n",
    "    #     eos=False,\n",
    "    # )\n",
    "    block_size = 2048  # this is for compat with gptq, and indeed we get much worse beyond this (https://github.com/facebookresearch/llama/blob/57b0eb62de0636e75af471e49e2f1862d908d9d8/llama/model.py#L30)\n",
    "    encoded_text = encoded_text[: n_samples * block_size].reshape(n_samples, block_size)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    llama_blockwise_quantization(model, encoded_text, device, bits=bits)\n",
    "    t = time.perf_counter() - t0\n",
    "\n",
    "    print(\n",
    "        f\"\\n\\nTime for quantization: {t:.02f} sec total\",\n",
    "        file=sys.stderr,\n",
    "    )\n",
    "    print(\n",
    "        f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\",\n",
    "        file=sys.stderr,\n",
    "    )\n",
    "    print(model.state_dict().keys())\n",
    "    checkpoint_2 = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': checkpoint['optimizer'],\n",
    "                    'model_args': checkpoint['model_args'],\n",
    "                    'iter_num': checkpoint['iter_num'],\n",
    "                    'best_val_loss': checkpoint['best_val_loss'],\n",
    "                    'config': checkpoint['config'],\n",
    "                }\n",
    "    print(f\"saving quantized model to {output_path}\")\n",
    "    torch.save(checkpoint_2, os.path.join(out_dir, output_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Time to load model: 0.13 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layer': 4, 'n_head': 16, 'n_embd': 256, 'block_size': 2048, 'bias': False, 'vocab_size': 50304, 'dropout': 0.0}\n",
      "RetNetConfig(block_size=2048, vocab_size=50304, n_layer=4, n_head=16, n_embd=256, dropout=0.0, bias=False)\n",
      "RetNet(\n",
      "  (embedding): Embedding(50304, 256)\n",
      "  (decoder): RetNetDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x RetNetDecoderLayer(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (retention): MultiScaleRetention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "          (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=256, out_features=50304, bias=True)\n",
      ")\n",
      "RetNetConfig(block_size=2048, vocab_size=50304, n_layer=4, n_head=16, n_embd=256, dropout=0.0, bias=False)\n",
      "Getting inputs for first block\n",
      "RetNetDecoder(\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x RetNetDecoderLayer(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (retention): MultiScaleRetention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "        (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "      (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Starting to quantize blocks\n",
      "0 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 2s quantization error 14.5\n",
      "0 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 14.5\n",
      "0 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 14.8\n",
      "0 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 15.0\n",
      "0 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 26.5\n",
      "0 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 1.4\n",
      "1 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 11.5\n",
      "1 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 11.5\n",
      "1 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 11.6\n",
      "1 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 11.9\n",
      "1 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 20.1\n",
      "1 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 1.5\n",
      "2 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 7.7\n",
      "2 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 7.7\n",
      "2 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 7.8\n",
      "2 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 7.9\n",
      "2 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 12.7\n",
      "2 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 1.2\n",
      "3 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 5.2\n",
      "3 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 5.2\n",
      "3 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 5.2\n",
      "3 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 5.4\n",
      "3 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 8.8\n",
      "3 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 1.0\n",
      "RetNet(\n",
      "  (embedding): Embedding(50304, 256)\n",
      "  (decoder): RetNetDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x RetNetDecoderLayer(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (retention): MultiScaleRetention(\n",
      "          (q_proj): ColBlockQuantizedLinear()\n",
      "          (k_proj): ColBlockQuantizedLinear()\n",
      "          (v_proj): ColBlockQuantizedLinear()\n",
      "          (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "          (g_proj): ColBlockQuantizedLinear()\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (linear1): ColBlockQuantizedLinear()\n",
      "        (linear2): ColBlockQuantizedLinear()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): ColBlockQuantizedLinear()\n",
      ")\n",
      "odict_keys(['embedding.weight', 'decoder.layers.0.norm1.weight', 'decoder.layers.0.norm1.bias', 'decoder.layers.0.retention.thetas', 'decoder.layers.0.retention.q_proj.bias', 'decoder.layers.0.retention.q_proj.weight', 'decoder.layers.0.retention.q_proj.scales', 'decoder.layers.0.retention.q_proj.zeros', 'decoder.layers.0.retention.k_proj.bias', 'decoder.layers.0.retention.k_proj.weight', 'decoder.layers.0.retention.k_proj.scales', 'decoder.layers.0.retention.k_proj.zeros', 'decoder.layers.0.retention.v_proj.bias', 'decoder.layers.0.retention.v_proj.weight', 'decoder.layers.0.retention.v_proj.scales', 'decoder.layers.0.retention.v_proj.zeros', 'decoder.layers.0.retention.g_proj.bias', 'decoder.layers.0.retention.g_proj.weight', 'decoder.layers.0.retention.g_proj.scales', 'decoder.layers.0.retention.g_proj.zeros', 'decoder.layers.0.retention.out_proj.weight', 'decoder.layers.0.retention.out_proj.bias', 'decoder.layers.0.norm2.weight', 'decoder.layers.0.norm2.bias', 'decoder.layers.0.linear1.bias', 'decoder.layers.0.linear1.weight', 'decoder.layers.0.linear1.scales', 'decoder.layers.0.linear1.zeros', 'decoder.layers.0.linear2.bias', 'decoder.layers.0.linear2.weight', 'decoder.layers.0.linear2.scales', 'decoder.layers.0.linear2.zeros', 'decoder.layers.1.norm1.weight', 'decoder.layers.1.norm1.bias', 'decoder.layers.1.retention.thetas', 'decoder.layers.1.retention.q_proj.bias', 'decoder.layers.1.retention.q_proj.weight', 'decoder.layers.1.retention.q_proj.scales', 'decoder.layers.1.retention.q_proj.zeros', 'decoder.layers.1.retention.k_proj.bias', 'decoder.layers.1.retention.k_proj.weight', 'decoder.layers.1.retention.k_proj.scales', 'decoder.layers.1.retention.k_proj.zeros', 'decoder.layers.1.retention.v_proj.bias', 'decoder.layers.1.retention.v_proj.weight', 'decoder.layers.1.retention.v_proj.scales', 'decoder.layers.1.retention.v_proj.zeros', 'decoder.layers.1.retention.g_proj.bias', 'decoder.layers.1.retention.g_proj.weight', 'decoder.layers.1.retention.g_proj.scales', 'decoder.layers.1.retention.g_proj.zeros', 'decoder.layers.1.retention.out_proj.weight', 'decoder.layers.1.retention.out_proj.bias', 'decoder.layers.1.norm2.weight', 'decoder.layers.1.norm2.bias', 'decoder.layers.1.linear1.bias', 'decoder.layers.1.linear1.weight', 'decoder.layers.1.linear1.scales', 'decoder.layers.1.linear1.zeros', 'decoder.layers.1.linear2.bias', 'decoder.layers.1.linear2.weight', 'decoder.layers.1.linear2.scales', 'decoder.layers.1.linear2.zeros', 'decoder.layers.2.norm1.weight', 'decoder.layers.2.norm1.bias', 'decoder.layers.2.retention.thetas', 'decoder.layers.2.retention.q_proj.bias', 'decoder.layers.2.retention.q_proj.weight', 'decoder.layers.2.retention.q_proj.scales', 'decoder.layers.2.retention.q_proj.zeros', 'decoder.layers.2.retention.k_proj.bias', 'decoder.layers.2.retention.k_proj.weight', 'decoder.layers.2.retention.k_proj.scales', 'decoder.layers.2.retention.k_proj.zeros', 'decoder.layers.2.retention.v_proj.bias', 'decoder.layers.2.retention.v_proj.weight', 'decoder.layers.2.retention.v_proj.scales', 'decoder.layers.2.retention.v_proj.zeros', 'decoder.layers.2.retention.g_proj.bias', 'decoder.layers.2.retention.g_proj.weight', 'decoder.layers.2.retention.g_proj.scales', 'decoder.layers.2.retention.g_proj.zeros', 'decoder.layers.2.retention.out_proj.weight', 'decoder.layers.2.retention.out_proj.bias', 'decoder.layers.2.norm2.weight', 'decoder.layers.2.norm2.bias', 'decoder.layers.2.linear1.bias', 'decoder.layers.2.linear1.weight', 'decoder.layers.2.linear1.scales', 'decoder.layers.2.linear1.zeros', 'decoder.layers.2.linear2.bias', 'decoder.layers.2.linear2.weight', 'decoder.layers.2.linear2.scales', 'decoder.layers.2.linear2.zeros', 'decoder.layers.3.norm1.weight', 'decoder.layers.3.norm1.bias', 'decoder.layers.3.retention.thetas', 'decoder.layers.3.retention.q_proj.bias', 'decoder.layers.3.retention.q_proj.weight', 'decoder.layers.3.retention.q_proj.scales', 'decoder.layers.3.retention.q_proj.zeros', 'decoder.layers.3.retention.k_proj.bias', 'decoder.layers.3.retention.k_proj.weight', 'decoder.layers.3.retention.k_proj.scales', 'decoder.layers.3.retention.k_proj.zeros', 'decoder.layers.3.retention.v_proj.bias', 'decoder.layers.3.retention.v_proj.weight', 'decoder.layers.3.retention.v_proj.scales', 'decoder.layers.3.retention.v_proj.zeros', 'decoder.layers.3.retention.g_proj.bias', 'decoder.layers.3.retention.g_proj.weight', 'decoder.layers.3.retention.g_proj.scales', 'decoder.layers.3.retention.g_proj.zeros', 'decoder.layers.3.retention.out_proj.weight', 'decoder.layers.3.retention.out_proj.bias', 'decoder.layers.3.norm2.weight', 'decoder.layers.3.norm2.bias', 'decoder.layers.3.linear1.bias', 'decoder.layers.3.linear1.weight', 'decoder.layers.3.linear1.scales', 'decoder.layers.3.linear1.zeros', 'decoder.layers.3.linear2.bias', 'decoder.layers.3.linear2.weight', 'decoder.layers.3.linear2.scales', 'decoder.layers.3.linear2.zeros', 'out.bias', 'out.weight', 'out.scales', 'out.zeros'])\n",
      "saving quantized model to ckpt_r_2048_q.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Time for quantization: 35.02 sec total\n",
      "Memory used: 3.20 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "\n",
      "As the man walked down the stairs, \n",
      "Was ranrate, I haveian our presence,\n",
      "Have you shall and meeting from heaven, which are amazed;\n",
      "And then IUGH both. For I could shortly,\n",
      "\n",
      "CORIET:\n",
      "WICK of that I say you do must be Paris\n",
      "Faith, my soul's,\n",
      "Would she knew barren served Polixenes the vap most truly is\n",
      "Than Hector:--auteous trusty bal.\n",
      "\n",
      "Second election, then begin; stones:\n",
      "It seems thou not jar come out.\n",
      "First Servant bears, and twenty years together,\n",
      "Your high, like civil cause dead is but\n",
      "No remedy of kings, a shrewdared no unt King Henry's eldest open thy heartily tenfold Edward.\n",
      "BALT:\n",
      "In this unmus's\n",
      "Within and honour to seek be satisfied!\n",
      "\n",
      "FLORIZABELLA liestent, the sunset up his blood!\n",
      "\n",
      "Ready and hanging,\n",
      "KING EDWARD:\n",
      "What is no more, you are going\n",
      "As now far off.\n",
      "GLOUCESTER:\n",
      "I'll be satisfied.\n",
      "\n",
      "\n",
      "\n",
      "QUEENI'll pity so fast sitting than what a\n",
      "And now!\n",
      "Second Servingman:\n",
      "Why, some ill, in his followers's knife is not high.\n",
      "\n",
      "His dullhip me, by their power incre, who;\n",
      "Were way, counsel;\n",
      "HORTENSIO: please our general nobles\n",
      "False, was just.\n",
      "\n",
      "GLOUCESTER:\n",
      "Go made this gentleman each brat on the rogue good crew'd\n",
      "As confident: good no more murdersals woful day\n",
      "As if the handledies and left me to wilt thou fly since\n",
      "Being tastedled soon,\n",
      "Look; God will proper stripling, my rapt, that's decay of Norfolk was common\n",
      "Conslong of his hands,\n",
      "Thus so I'll find his head.\n",
      "The same life thou to the Montagueand us!\n",
      "KING HENES:\n",
      "Now two hand he shall hold.\n",
      "\n",
      "MERCAMILLO woful seems. My shipsant shrift when thou hast cause.\n",
      "CLAUDIO:\n",
      "The contents and the physician word give him came in a little car spoke.\n",
      "\n",
      "BUCKINGHAM:\n",
      "My lord, fair but one, I could be endured is, we,\n",
      "In Brittany is the soldiers, and faint friends:\n",
      "You lose we knew the Duke of Verona,\n",
      "ent knifehed me stands.\n",
      "\n",
      "ANGELBUCKINGHAM:\n",
      "Ch--which something colours shookpp and I pray,\n",
      "Your mother's conscience tells to my lord!\n",
      "And throw, and holy Ne,\n",
      "which unable conscience now thee.\n",
      "GLOUCESTER:\n",
      "Marry, gentle friends\n",
      "STANLEY: If I warrant they say, metal a great gentle words;\n",
      "Yet says your voices, for his chief\n",
      "I am\n",
      "That newona mar less hand:\n",
      "Unto; thereto be mad'd:\n",
      "Looks; so it post unto my hearts,\n",
      "Come, my good Mercutio,\n",
      "As I will, grant you have an unpeople villain his wife forfeit,\n",
      "To graced of brown knife! You leave us\n",
      "To scarlet.\n",
      "\n",
      "JULI promised, marry, stand in pity, my side-up is dead to sear goodness could grow.\n",
      "\n",
      "Clarewell.\n",
      "The injuryably you, my good, do not?\n",
      "QUEEN ELIZABRAKENBURY CAPULET:\n",
      "Madam;\n",
      "Whither is a present with that happiness of death outweigh. But were\n",
      "To their drums us min;\n",
      "Before by his All-hand Paris to comfort\n",
      "Daked for your majesty as true thousandinius.\n",
      "\n",
      "LADYea, even was whe other ground!\n",
      "\n",
      "LORD:\n",
      "CES:\n",
      "And remember, if thou had.\n",
      "\n",
      "\n",
      "HASTINGS:\n",
      "We may she comes a kind\n",
      "And said be none;\n",
      "And's good lord; and friends that put her with love,\n",
      "To rage, come on the stamp,\n",
      "Set's increase him pass thy glories.\n",
      "To great; if we see their power to make us,\n",
      "Thanio'st and babe:\n",
      "This news, as thou I have not ext,\n",
      "And mercy mis sway? make those dear lord, the greaterid than here! why thee be\n",
      "\n",
      "CORI thank you do remain against it is pawn.\n",
      "The crown.\n",
      "Second Murderer:\n",
      "'Tush the virtue.\n",
      "\n",
      "\n",
      "First Senator:\n",
      "Indeed, but when pardon me with lament and name day Warwick,,\n",
      "his bring me, prince:\n",
      "Is thicker Duke, in Verona up to the vantage made her?\n",
      "And teach were she lives,, that box?\n",
      "\n",
      "KING RICH\n",
      "---------------\n",
      "Elapsed time: 19.815447568893433\n",
      "\n",
      "As the man walked down the stairs, CA:\n",
      "So as easy nature truly the king?  to break within his fair,\n",
      "All:\n",
      "And awhile!\n",
      "\n",
      "First Citizen:\n",
      "O, where she were a happy serve:\n",
      "To cheque more mine father to be good,\n",
      "And he's butt.\n",
      "\n",
      "LORD WILLOUGHBY:\n",
      "Not to be too bold with him; why,\n",
      "I was born themselves must be stretch, i'Twas,\n",
      "And let the welcome, and boy; but too much--as,\n",
      "As rank malice of my wife;\n",
      "The bold after prophecies'd before, as grosser be counted,\n",
      "Is dishonour again'd these old queen?\n",
      "WICK: mine beggar,\n",
      "We'll frowns,\n",
      "GLOUCESTER:\n",
      "He dies to market you make you well.\n",
      "\n",
      "No, no cause. At against the; follow!\n",
      "\n",
      "KING HENVOLIO:\n",
      "Madam pepp of potency,\n",
      "Now, hear the feast.\n",
      "Come, my George's none.\n",
      "\n",
      "ROMEO:\n",
      "Mistake me:\n",
      "We nor a thing dry you and his body,\n",
      "\n",
      " Frious stoop.\n",
      "KING ROSS:\n",
      "Next his penitent another, and my lords;\n",
      "To fine musician:\n",
      "Even eyes at our reasons, graftedst weighing-burning\n",
      "What'st too hot col blows it? Daughter a js?\n",
      "\n",
      "LEONTESCATESBY:\n",
      "You hear me. How seen they could hear you ancient time of kon,\n",
      "O, Bushy to his sense not pass\n",
      "sentenced, noble deeds! O, to be gold no more such duke?\n",
      "JULIET:\n",
      "That I will bear the devilly sun;\n",
      "JULI promised for all wail let's name; is nay,\n",
      "And fell is my mother hath you know I see your hand shall become your son you talk.\n",
      "DUKE VINCENTIO:\n",
      "He says crown! What the gods!\n",
      "\n",
      "CLARENCE:\n",
      "O,'Remember not Romeo, hath been pity are mine honour have access,\n",
      "And yet a grain hath been blueic; I may be in mind\n",
      "And, till now, God's bloody axe the Lord venom my father be sworn.\n",
      "\n",
      "PAULI there never run allegiance it? 'tis pitiful him last.\n",
      "FLORIZABETH:\n",
      "King the Sixth for these of Buckingham\n",
      "They know not pray, atkins,\n",
      "And cowardly, that hath fall the air is a need,\n",
      "Or Marcius, where have be so still you both you did supply,\n",
      "hest fix thou sure to the blood.\n",
      "\n",
      "TYBUCKINGHAM:\n",
      "I speak in France, my brother Montague have\n",
      "Between; never make; alas is just proportion, God!--, with strokes. I'll bring him\n",
      "As the indictmentERLEONTES:\n",
      "To have mounted in the common i' me grace\n",
      "Even atonement where should say 'ail inevitable his regiment edge,\n",
      "A Germans:\n",
      "Whose so not; not for this, to the tub, my liege,\n",
      "And I have let her dowry,\n",
      "Wert like an oak, when these no more call me,\n",
      "Which I see our trow in the best\n",
      "And, marry--\n",
      "Even thou livest:\n",
      " cookongue what miscar!\n",
      "Unless his highness! how he was the gods?\n",
      "\n",
      "Second Citizen:\n",
      "Each no doubt would the good Paulina for a hovering;\n",
      "And for certainer till you must thou liestous tax flap,\n",
      "Edward but vain had that there thy kingdom may be night\n",
      "Two props, as fartiny. What, the world.\n",
      "SICINIUS:\n",
      "I be tainted God towards Ber!' Why men like a bawdy,\n",
      "We? Come. But, by thy sacred appointment my crown.\n",
      "All\n",
      "GLOUCESTER:\n",
      "A:\n",
      "Be it pleasORY, the fee here,\n",
      "His life.\n",
      "SICINI am a word, but thought are they saw it: pray,\n",
      "I would be obeyly.\n",
      "\n",
      "\n",
      "MENENRY VI:\n",
      "I conjure, let you are ter such he'st the harmless me upon him\n",
      "Shall report of them,\n",
      "And he.\n",
      "Is we her well can, what sa. Spirits,\n",
      "He hath welcome. He o' the stripes impress, Lord: he must know.\n",
      "When you to see it\n",
      "Lo, sir:\n",
      "What; I was wrecked were the king larg opeed mother,\n",
      "Did myself for a bay:\n",
      "He would her beefagems in the last we have stay dinner of blame,\n",
      "A cherry name, were not yet. The the Adieu to linger,\n",
      "thee\n",
      "That modesty my kingdom lost a score that can\n",
      "---------------\n",
      "Elapsed time: 19.817535400390625\n",
      "\n",
      "As the man walked down the stairs,  thereof you'Red's shape and--\n",
      "To Romeo\n",
      "How with your thought his good fools upon you;\n",
      "Where's good delect the bastard, good\n",
      "As me.\n",
      "MENENIUS:\n",
      "Pise he will? know, some gone the deliveries, now it.\n",
      "\n",
      "PAULIUS:\n",
      "HENIOLINGHAM: look she possible for the witness that\n",
      "To yet I will it out me but by the blood,\n",
      "Whate confess to beseech, to the common man.\n",
      "\n",
      "KING EDWARD:\n",
      "Indeed is the king, why against his looks with his book have the prevention,\n",
      "When I will have an egg,\n",
      "And Rice banish Barn task; prove,.\n",
      "\n",
      "GLOUCESTER:\n",
      "They, my griefs.\n",
      "\n",
      "ROMEO:\n",
      "Think you married this castle.\n",
      "MENENI'll be:\n",
      "I will.\n",
      "\n",
      "\n",
      "QUEENIUS:\n",
      "The executioner.\n",
      "\n",
      "LADY:\n",
      "O: what is true, but for such stand'd,\n",
      "Return.\n",
      "\n",
      "KING EDWARD IV:\n",
      "He are gone, yea, more, but I woo.\n",
      "\n",
      "PAULIUS:\n",
      "Ay; but we should speak from your\n",
      "To look your words\n",
      "Thy mountain:\n",
      "Good sadness! What should be dyed this hang accusation.\n",
      "\n",
      "ISABETH:\n",
      "O my lord, my headited general,\n",
      "Which at Saint Alban, and a villain's from the title;\n",
      "And I have done, depart by you'd forth greater:\n",
      "My lord,\n",
      "Betaunting moon makes Richmond say back for because his honour\n",
      "CUTUS:\n",
      "I willlets you shall weep. Cot on the deputy. Art against this teeming!\n",
      "\n",
      "CORIOLYCUS:\n",
      "O and dreams, but to horse of a many hours:\n",
      "And they break them, my lord.\n",
      "All the rocks love, God save a bridal,\n",
      "Like offices me, yet our mind's kings?\n",
      "\n",
      "First Watchman, Juliet, never, they are thus!\n",
      "\n",
      "GLOUCESTER:\n",
      "A whispering VINCENTIO:\n",
      "I call'd my lord, but sheafter that calls;\n",
      "Tell him, call thee,\n",
      "When it with the good flock, let us all\n",
      "Are as great men are no lips:\n",
      "Be you were men Ned me consul be aged\n",
      "Which in another conduct to hear this breathingle Buckingham,\n",
      "Angelo impregn me, split the fruit about you two\n",
      "But to me of the house.\n",
      "\n",
      "Desmen, I will command.\n",
      "\n",
      "CLIFFORD:\n",
      "LADY ANNE: how she's most coursers down\n",
      "Each. Your us be on towards Ber VINCENTIO:\n",
      "Now each brother, forget for God--\n",
      "\n",
      "weared she leans my poor souls.\n",
      "Lascivant:\n",
      "My seeming! good time:\n",
      "Sirrah, no more, by some giddy my soul:\n",
      "And thus much cherishing why, your pleasure,\n",
      "Or here, go to signify,--\n",
      "A marble, and let us; but reprehend.\n",
      "\n",
      "QUEENVOL years, hear; and clubs?\n",
      "Come, your ways\n",
      "GAR PET than tigers by advised.\n",
      "\n",
      "DONE:\n",
      "What says a maniest,\n",
      "And I would thou hast though it a dost: as the lords!\n",
      "Then fall of one place I hear\n",
      "\n",
      "And keep him henceforth did I know you nod from thy love\n",
      "pleaseuck them,\n",
      "Evenness harness as newuncheon; she may owe a book not well.\n",
      "\n",
      "KING EDWARD:\n",
      "It was pawn, I know that rests.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "No doubt\n",
      "T: one for I have heard\n",
      "Banish their lives; or goddess\n",
      "All praise you had he were so well, that is bloody axe\n",
      "But I cannot get, set on their taking withdraw in their cob\n",
      "true imagine when they are pleasant to enter'd with showers,\n",
      "Oriety as they took this is me, and speed,\n",
      "And by blood!\n",
      "Will soon of these his child, curse'd with corns, take the whole mother's waxly all even in post,\n",
      "I have been a snowy King Marcius,\n",
      "Even trimm us acquaint, that our way for the fiery-by shall deliver him.\n",
      "And he say you rather hearts constant her soul\n",
      "Lordsed terror man!\n",
      "I think's land it be for charity! You dream, that thou split.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "To link's slipperyed use\n",
      "I enjoy, now and great history\n",
      "Cut that men is here about Richard.\n",
      "\n",
      "QUEEN MARGARENCE:\n",
      "One not now far can make thyself to\n",
      "---------------\n",
      "Elapsed time: 20.604463577270508\n",
      "\n",
      "As the man walked down the stairs, ited cloth your bands the thoughts'd\n",
      " Paris'nu wound rich'd prempireous me and as you so sc joys the grievous give you gave thee with the women from thences\n",
      "In; 'BISHOP souls,\n",
      "As thou.' unto this All cuck comes to go along.\n",
      "\n",
      "Why are your dishonour, though I could have worst you; can sol\n",
      "Andocund fav: deal! I hear some songs, if you, but more\n",
      "Win! a blush are thou hast thou in Hol,\n",
      "Thou sleense from his king? suffer treaty.\n",
      "\n",
      "LEONTESCUTUS:\n",
      "He must confess so.\n",
      "And let me! no head? Where cousin;\n",
      "Where should have this palpable's face!\n",
      "WICK: but to think:\n",
      "No be thus that you find\n",
      "And brought.\n",
      "\n",
      "POLIXENI'll meet you see the concally!\n",
      "Nurse:\n",
      "And that me the cause's poor wormies,\n",
      "For in chase\n",
      " enemy I tell yet had return of him hide it, farewell. Come-term upon thy looks; but securely\n",
      "With branches overwhelming.\n",
      "HENIET:\n",
      "I give their heads:\n",
      "Do you are not for you married, thou never hear it?\n",
      "\n",
      "\n",
      "Messenger:\n",
      "I think I am put from your husband. He desires to't best us but for your rude.\n",
      "\n",
      "\n",
      "LUCIO:\n",
      "We set me no quarrel, no hope but you\n",
      "WICK: the house:\n",
      "Warwick.\n",
      "Why, am for Rome, here entail you lean taken nor more,\n",
      "To think's pardon and well assured\n",
      "DERBY: pray, took\n",
      "That's tears would, that most admired the honour your daughter upon thee hence. But's back.\n",
      "\n",
      "LARTI amorous of her,\n",
      "QUEENRY VI: but he would not.\n",
      "\n",
      "GLOUCESTER:\n",
      "But sound, arm into the Dukeful' the state,\n",
      "In this night is't,\n",
      "SICINI would win the world of thy father's,\n",
      "Which as I will wear the visitation their issues.\n",
      "GLOUCESTER:\n",
      "Richard the prayer and furious,\n",
      "Then countermand fit of Exeter sleep. I make,\n",
      "Then, sir.\n",
      "CES:\n",
      "How twentyernest.\n",
      "CLARENCE:\n",
      "Why are quickly there Duke of your great brought you\n",
      "From whence my poor Montague are else you are no poison\n",
      "\n",
      "LADY:\n",
      "Tell us assail un lamenters in your ways;\n",
      "t no, sir, and do you have him with your son,\n",
      "The vap seas, what she hath conveyed came.\n",
      "\n",
      "MENENI call'd tr lips, that amissant! confusion.\n",
      "\n",
      "GLOUCESTER:\n",
      "Ay.\n",
      "Second Keeper:\n",
      "Then's forsworn.\n",
      "\n",
      "\n",
      "LEONTES:\n",
      "Gall:\n",
      "No honour!\n",
      "Second Keeper:\n",
      "Sold\n",
      "Second Citizen:\n",
      "I indeed's, gracious lord, sir, you as soon since you\n",
      "Like her beef?\n",
      "\n",
      "COMINI'Twere her and Camillo.\n",
      "\n",
      "BRUTUS:\n",
      "A:\n",
      "os aspect but I like death nor an oy\n",
      "And I myself, how the ratherled most wicked:\n",
      "Good morrow of I must keep\n",
      "No, who speaks the goose, and honour,\n",
      "itently negative, that shall I am a shame to life\n",
      "And give their breed; but rather done this? ELY of this boy.\n",
      "\n",
      "Lilia are more dangerous you have power a\n",
      "Where be revenged in their swelling\n",
      "May lie in him did spendier memberus.\n",
      "Of me are the smallio, and familiar.\n",
      "\n",
      "LORD:\n",
      "O Clifford on thy news's this good madam, and victory!\n",
      "And not him that he is kill my fair hold it\n",
      "In thee drums:\n",
      "In our talk only Richard inwixt thee,\n",
      "fortune, so, well the earth!--\n",
      "As you.\n",
      "\n",
      "MENENESCUTUS:\n",
      "O:\n",
      "Yes, sir, I'll take content:\n",
      "I have enter up sir, kill'd in thy name in presence\n",
      "Which,\n",
      " goat that forswear Kath newly sell you! what are richs the furthe of most frantic\n",
      "And what a word; more him readyces.\n",
      "\n",
      "NIA:\n",
      "No, my masters, but call them still ne'Z in his son the other senses?\n",
      "\n",
      "KING RICHARD II:\n",
      "Ay, here, watch dost.\n",
      "\n",
      "MENENESCame, you by that name, this gentleman.\n",
      "\n",
      "GLOUCES:\n",
      "This best elders your Sicilia,\n",
      "And though you, O woful haught\n",
      "Whom thought he were opposite blow and\n",
      "---------------\n",
      "Elapsed time: 20.732424020767212\n",
      "\n",
      "As the man walked down the stairs, ,\n",
      "Some that, there with that harlot\n",
      "CUT:\n",
      "EndOMERSET:\n",
      "GARET: prepare the merry. Be'd in yonder myself it well resembles,\n",
      "Come on this foulioli.\n",
      "\n",
      "KING EDWARD IV:\n",
      "RUKE OF YORK:\n",
      "Chargeswray and all our recompense me!\n",
      "\n",
      "Second Messenger:\n",
      "HORTENS:\n",
      "O thou dip that the beastles\n",
      "Biedberpt man her wilt by the grave--\n",
      "too do not banished.\n",
      "\n",
      "POLIXENVOLUMNay, I will sear.\n",
      "\n",
      "SAMPSONUS:\n",
      "These flight is nor hurts up an angry,\n",
      "Thy, but the circumstance that mew'd could the spic me,\n",
      "Show-like prank promises than we pity,\n",
      "Even to us as anointed?\n",
      "\n",
      "ROMEO:\n",
      "There's but only any is differe with envy; which concerns,\n",
      "And now as the Ten Command do not,\n",
      "Renowned! my friends, our trifling; swallowed, if the golden beams was gone,\n",
      "Against this varlet soul's Captain us hence,\n",
      "Which he speaks love your lark.\n",
      "And thou in the souls to curse\n",
      "Welcome; every flawaceued, I fear'd him be our tenly presence\n",
      "Tyboding of by my lord chamberlain and slaves;\n",
      "And I speak more\n",
      "And with honey my bonds with some Paris and rude by God's enmish'd back!\n",
      "Witness nay, my dear employment one make your head of wretched sweet Clifford;\n",
      "Which,3 KING HENI see her right of my death?\n",
      "The ground in themselves thy revenge whipt and will's frowns away, or soldier,\n",
      "With thousands by the hair\n",
      "Shot valiant foeman thou doth grin in any thing\n",
      "Tow careenced unre a weakath here will do so o'rt?\n",
      "\n",
      "\n",
      "LORD WILLOUGHBY:\n",
      "I'll keep that this appeal'd.\n",
      "\n",
      "GREGardine,\n",
      "GLOUCESTER:\n",
      "If I can bring the latter touch'd with the adverse within\n",
      "To be leisure not,\n",
      "good my friends. But I know no priest's house;\n",
      "begot; go our seal he weighs atainted's not mock'd the queen,\n",
      "Whose house of victory:\n",
      "Forysny our convent, but yet and the prince as her!\n",
      "Thy time on love, when I now, thy tongue\n",
      "Nor brass of Edward's substitute time\n",
      "How thy secondary enough,\n",
      "And did suffer your father.\n",
      "ROMEO:\n",
      "Men my success ripe spent, by any language call him,\n",
      "That I may follow me mistrust no delight their hearts.\n",
      "\n",
      "\n",
      "Justice to her actions; yet it were all that in my friends\n",
      "Witness.\n",
      "GLOUCESTER:\n",
      "Now thou what we pardon by Saint George of the book:\n",
      "Your nativeELO,\n",
      "The lands\n",
      "Were hasty these witnesses that worthy,\n",
      "That they strike for these articles Kathashre look't.\n",
      "NORTHUMNIA:\n",
      "He hath I,\n",
      "To her state.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Were none: the meaning, if he is meant hereby he wore's wife was highness: most let him to know me before it,\n",
      "And calf of all: therefore: O, unprofew of late;\n",
      "HORTENSIO:\n",
      "I do, will her husband? cut ashore,\n",
      "MONTAGUEENI had you gone.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What say 'tis a vision I,\n",
      "Nor time. Clarence his.\n",
      "Volsce:\n",
      "To die:\n",
      "O, is the Duke this sparing it uncles, when I found the breath is here's mine.\n",
      "Sometime child and Mistress\n",
      "ROMEO: contempt, come's day,\n",
      "Stabb; then the times thee, wisdom wilt\n",
      "From string on Hereford's head, he,\n",
      "Before even or, haproud?\n",
      "\n",
      "CORIUS:\n",
      "What said, will hast haz with the city;\n",
      "My gracious wounds to shame to your Lady Grey?\n",
      "POMPEYORK-heart you how far Bianca\n",
      "Fall lump that is do stand to do wrong, pity.\n",
      "\n",
      "\n",
      "MENENIUS: but ask'd? Has; good my guestsr the queen!\n",
      "\n",
      "AUFIDI am Catesby a monster thee doth\n",
      "And the eye\n",
      "Such her way thy crowns quaint, were this year,\n",
      "That thou doth this offence him.\n",
      "\n",
      "Second Citizen:\n",
      "Godangling with myself'dedief choler at thyself,\n",
      "Here's the foe up an endures upon thence,\n",
      "Thou gracious bulk we wish,\n",
      "To be put between this realm except, to England\n",
      "---------------\n",
      "Elapsed time: 20.024667263031006\n",
      "[19.815447568893433, 19.817535400390625, 20.604463577270508, 20.732424020767212, 20.024667263031006]\n",
      "20.198907566070556\n"
     ]
    }
   ],
   "source": [
    "model_8bit = quantizing(output_path=model_name[:-3] + '_q.pt', quantize='gptq.int8')\n",
    "model_8bit.to(device)\n",
    "\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "decode = lambda l: enc.decode(l)\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "# run generation\n",
    "time_per_sample = []\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            start_time = time.time()\n",
    "            y = model_8bit.generate_parallel(x, max_new_tokens, temperature=temperature)\n",
    "            #print(y)\n",
    "            print(decode(y[0].tolist()))\n",
    "            end_time = time.time()\n",
    "            print('---------------')\n",
    "            duration = end_time - start_time\n",
    "            print(f\"Elapsed time: {duration}\")\n",
    "            time_per_sample.append(duration)\n",
    "print(time_per_sample)\n",
    "print(sum(time_per_sample) / len(time_per_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layer': 4, 'n_head': 16, 'n_embd': 256, 'block_size': 2048, 'bias': False, 'vocab_size': 50304, 'dropout': 0.0}\n",
      "RetNetConfig(block_size=2048, vocab_size=50304, n_layer=4, n_head=16, n_embd=256, dropout=0.0, bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time to load model: 0.24 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetNet(\n",
      "  (embedding): Embedding(50304, 256)\n",
      "  (decoder): RetNetDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x RetNetDecoderLayer(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (retention): MultiScaleRetention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "          (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=256, out_features=50304, bias=True)\n",
      ")\n",
      "RetNetConfig(block_size=2048, vocab_size=50304, n_layer=4, n_head=16, n_embd=256, dropout=0.0, bias=False)\n",
      "Getting inputs for first block\n",
      "RetNetDecoder(\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x RetNetDecoderLayer(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (retention): MultiScaleRetention(\n",
      "        (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "        (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "      (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Starting to quantize blocks\n",
      "0 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 4197.7\n",
      "0 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 4211.3\n",
      "0 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 4280.4\n",
      "0 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 4362.0\n",
      "0 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 7655.2\n",
      "0 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 427.6\n",
      "1 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 3329.4\n",
      "1 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 3329.8\n",
      "1 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 3341.7\n",
      "1 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 3467.3\n",
      "1 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 5812.5\n",
      "1 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 437.8\n",
      "2 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 2236.0\n",
      "2 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 2258.5\n",
      "2 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 2249.2\n",
      "2 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 2317.9\n",
      "2 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 3674.5\n",
      "2 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 363.4\n",
      "3 retention.q_proj collecting stats quantizing ColBlockQuantizedLinear() retention q_proj\n",
      "time 1s quantization error 1523.2\n",
      "3 retention.k_proj collecting stats quantizing ColBlockQuantizedLinear() retention k_proj\n",
      "time 1s quantization error 1500.5\n",
      "3 retention.v_proj collecting stats quantizing ColBlockQuantizedLinear() retention v_proj\n",
      "time 1s quantization error 1511.7\n",
      "3 retention.g_proj collecting stats quantizing ColBlockQuantizedLinear() retention g_proj\n",
      "time 1s quantization error 1533.1\n",
      "3 linear1 collecting stats quantizing ColBlockQuantizedLinear() linear1\n",
      "time 1s quantization error 2521.6\n",
      "3 linear2 collecting stats quantizing ColBlockQuantizedLinear() linear2\n",
      "time 2s quantization error 296.2\n",
      "RetNet(\n",
      "  (embedding): Embedding(50304, 256)\n",
      "  (decoder): RetNetDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x RetNetDecoderLayer(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (retention): MultiScaleRetention(\n",
      "          (q_proj): ColBlockQuantizedLinear()\n",
      "          (k_proj): ColBlockQuantizedLinear()\n",
      "          (v_proj): ColBlockQuantizedLinear()\n",
      "          (group_norm): GroupNorm(16, 256, eps=1e-06, affine=False)\n",
      "          (g_proj): ColBlockQuantizedLinear()\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (linear1): ColBlockQuantizedLinear()\n",
      "        (linear2): ColBlockQuantizedLinear()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): ColBlockQuantizedLinear()\n",
      ")\n",
      "odict_keys(['embedding.weight', 'decoder.layers.0.norm1.weight', 'decoder.layers.0.norm1.bias', 'decoder.layers.0.retention.thetas', 'decoder.layers.0.retention.q_proj.bias', 'decoder.layers.0.retention.q_proj.weight', 'decoder.layers.0.retention.q_proj.scales', 'decoder.layers.0.retention.q_proj.zeros', 'decoder.layers.0.retention.k_proj.bias', 'decoder.layers.0.retention.k_proj.weight', 'decoder.layers.0.retention.k_proj.scales', 'decoder.layers.0.retention.k_proj.zeros', 'decoder.layers.0.retention.v_proj.bias', 'decoder.layers.0.retention.v_proj.weight', 'decoder.layers.0.retention.v_proj.scales', 'decoder.layers.0.retention.v_proj.zeros', 'decoder.layers.0.retention.g_proj.bias', 'decoder.layers.0.retention.g_proj.weight', 'decoder.layers.0.retention.g_proj.scales', 'decoder.layers.0.retention.g_proj.zeros', 'decoder.layers.0.retention.out_proj.weight', 'decoder.layers.0.retention.out_proj.bias', 'decoder.layers.0.norm2.weight', 'decoder.layers.0.norm2.bias', 'decoder.layers.0.linear1.bias', 'decoder.layers.0.linear1.weight', 'decoder.layers.0.linear1.scales', 'decoder.layers.0.linear1.zeros', 'decoder.layers.0.linear2.bias', 'decoder.layers.0.linear2.weight', 'decoder.layers.0.linear2.scales', 'decoder.layers.0.linear2.zeros', 'decoder.layers.1.norm1.weight', 'decoder.layers.1.norm1.bias', 'decoder.layers.1.retention.thetas', 'decoder.layers.1.retention.q_proj.bias', 'decoder.layers.1.retention.q_proj.weight', 'decoder.layers.1.retention.q_proj.scales', 'decoder.layers.1.retention.q_proj.zeros', 'decoder.layers.1.retention.k_proj.bias', 'decoder.layers.1.retention.k_proj.weight', 'decoder.layers.1.retention.k_proj.scales', 'decoder.layers.1.retention.k_proj.zeros', 'decoder.layers.1.retention.v_proj.bias', 'decoder.layers.1.retention.v_proj.weight', 'decoder.layers.1.retention.v_proj.scales', 'decoder.layers.1.retention.v_proj.zeros', 'decoder.layers.1.retention.g_proj.bias', 'decoder.layers.1.retention.g_proj.weight', 'decoder.layers.1.retention.g_proj.scales', 'decoder.layers.1.retention.g_proj.zeros', 'decoder.layers.1.retention.out_proj.weight', 'decoder.layers.1.retention.out_proj.bias', 'decoder.layers.1.norm2.weight', 'decoder.layers.1.norm2.bias', 'decoder.layers.1.linear1.bias', 'decoder.layers.1.linear1.weight', 'decoder.layers.1.linear1.scales', 'decoder.layers.1.linear1.zeros', 'decoder.layers.1.linear2.bias', 'decoder.layers.1.linear2.weight', 'decoder.layers.1.linear2.scales', 'decoder.layers.1.linear2.zeros', 'decoder.layers.2.norm1.weight', 'decoder.layers.2.norm1.bias', 'decoder.layers.2.retention.thetas', 'decoder.layers.2.retention.q_proj.bias', 'decoder.layers.2.retention.q_proj.weight', 'decoder.layers.2.retention.q_proj.scales', 'decoder.layers.2.retention.q_proj.zeros', 'decoder.layers.2.retention.k_proj.bias', 'decoder.layers.2.retention.k_proj.weight', 'decoder.layers.2.retention.k_proj.scales', 'decoder.layers.2.retention.k_proj.zeros', 'decoder.layers.2.retention.v_proj.bias', 'decoder.layers.2.retention.v_proj.weight', 'decoder.layers.2.retention.v_proj.scales', 'decoder.layers.2.retention.v_proj.zeros', 'decoder.layers.2.retention.g_proj.bias', 'decoder.layers.2.retention.g_proj.weight', 'decoder.layers.2.retention.g_proj.scales', 'decoder.layers.2.retention.g_proj.zeros', 'decoder.layers.2.retention.out_proj.weight', 'decoder.layers.2.retention.out_proj.bias', 'decoder.layers.2.norm2.weight', 'decoder.layers.2.norm2.bias', 'decoder.layers.2.linear1.bias', 'decoder.layers.2.linear1.weight', 'decoder.layers.2.linear1.scales', 'decoder.layers.2.linear1.zeros', 'decoder.layers.2.linear2.bias', 'decoder.layers.2.linear2.weight', 'decoder.layers.2.linear2.scales', 'decoder.layers.2.linear2.zeros', 'decoder.layers.3.norm1.weight', 'decoder.layers.3.norm1.bias', 'decoder.layers.3.retention.thetas', 'decoder.layers.3.retention.q_proj.bias', 'decoder.layers.3.retention.q_proj.weight', 'decoder.layers.3.retention.q_proj.scales', 'decoder.layers.3.retention.q_proj.zeros', 'decoder.layers.3.retention.k_proj.bias', 'decoder.layers.3.retention.k_proj.weight', 'decoder.layers.3.retention.k_proj.scales', 'decoder.layers.3.retention.k_proj.zeros', 'decoder.layers.3.retention.v_proj.bias', 'decoder.layers.3.retention.v_proj.weight', 'decoder.layers.3.retention.v_proj.scales', 'decoder.layers.3.retention.v_proj.zeros', 'decoder.layers.3.retention.g_proj.bias', 'decoder.layers.3.retention.g_proj.weight', 'decoder.layers.3.retention.g_proj.scales', 'decoder.layers.3.retention.g_proj.zeros', 'decoder.layers.3.retention.out_proj.weight', 'decoder.layers.3.retention.out_proj.bias', 'decoder.layers.3.norm2.weight', 'decoder.layers.3.norm2.bias', 'decoder.layers.3.linear1.bias', 'decoder.layers.3.linear1.weight', 'decoder.layers.3.linear1.scales', 'decoder.layers.3.linear1.zeros', 'decoder.layers.3.linear2.bias', 'decoder.layers.3.linear2.weight', 'decoder.layers.3.linear2.scales', 'decoder.layers.3.linear2.zeros', 'out.bias', 'out.weight', 'out.scales', 'out.zeros'])\n",
      "saving quantized model to ckpt_r_2048_q.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Time for quantization: 35.12 sec total\n",
      "Memory used: 3.20 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "\n",
      "As the man walked down the stairs,  and teachmen and what,\n",
      "Seal dreadful irCLAR PETERLE:\n",
      "Cons were of you no more gone, would may.\n",
      "What be done, then be strength yet there to live.\n",
      "\n",
      "First Citizen:\n",
      "FRIARENCE:\n",
      "A shadow our fault indifferent! why\n",
      "KING RICHARD III:\n",
      "Well, never talk of death and that long of want thou art night.\n",
      "\n",
      "\n",
      "YORK:\n",
      "I conj's good your many time will strongly;\n",
      "Said talk of kings restitution, not priv, see my see pathways and he\n",
      "Outlive'? Hang them together: what title of the m scales\n",
      "Ready to acquaint your will bewe most stifle the son\n",
      "Or murderounceanderersmen-freto, lower my,\n",
      "That they say. Hang of ease her most unjust gold,\n",
      "For girlsue you restore's glory!\n",
      "TRANLEY:\n",
      "Here comes that calls, ha: subjected him whose plots.\n",
      "It was not in the word, that thou that vice!\n",
      "By deceived, bones is dead, he that,\n",
      "and a thousandout of onearewell it befall him\n",
      "Against\n",
      "Come belie. So forward I am resolved it and\n",
      "\n",
      "GLOUCALUS:\n",
      "Ah, he wakes and his queen,\n",
      "Go!\n",
      "Have youET:\n",
      "Good nature's God? O sorrow, must speak\n",
      "Did never in my suitors, and they have sped and you swear again.\n",
      "GAR PETER:\n",
      "SICINIOLYCUS: let you,\n",
      "By their trothence?\n",
      "\n",
      "First Lord Hastings is were no flock, shall see him.\n",
      "\n",
      "KING RICHARD:\n",
      "ISABETH:\n",
      "Ay, and that thou my son,\n",
      "The precious father's Bohemia till 'twere my garland?\n",
      "\n",
      "RUTUS:\n",
      "The hourless and entreat sweet bait, and\n",
      "My bounty Lord Angelo of York\n",
      "QUEEN MARGARET: well they as a marvel.\n",
      "\n",
      "SIR STEPert satisfied in plain,\n",
      "Then strike with the painful, that their own boon lost,\n",
      "all his neighbour.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Each, for them both: Carlisle.\n",
      "\n",
      "KING HENI know it.\n",
      "LUCIO:\n",
      "Not for our good lord; Duke of Lancaster thy unreverend into keep upon you\n",
      "'en call's. Let us can join,--\n",
      "\n",
      "LUCIO:\n",
      "That I, Signior Hortensio behold thee,\n",
      "Proud as\n",
      "All sometime stirring.\n",
      "DORSET:\n",
      "Are I left.\n",
      "\n",
      "ESCAMILLO:\n",
      "Good love; you shall not shall we do 'tis.\n",
      "\n",
      "MENEN MARGARET:\n",
      "QUEENRY VI: remember stir'd no oath and all the court Clarence;\n",
      "So many days wandering\n",
      "And do death, Comin not be satisfied, wilt they do me be done?\n",
      "Now were this intelligence the place,\n",
      "Moreth, Paulina than you love with his lion the name?\n",
      "\n",
      "If thou went him, murder for her desperate him, will cheer'd at nine,\n",
      "Which my lord, part and read.\n",
      "\n",
      "Would have assembled, I lay. At;\n",
      "Where'st; brookions, be promised for their harms-horse, gra thee,\n",
      "And say's chamber for,\n",
      "And presently to haste; for double Jack's effect\n",
      "And now-faceder to the jealous hood his hence,\n",
      "The a sudden gentle Claudio with an end\n",
      "I am glad off.\n",
      "As if thine heirs my lie.\n",
      "\n",
      "\n",
      "ANGELO, prince,\n",
      "Te is seizedches match;\n",
      "And nothing fear.\n",
      "\n",
      "And ne' report of York hath ta' testimonies tongue's one,\n",
      "For here to life.\n",
      "POLIXENIUS:\n",
      "What is rather, Montague of England in prayer\n",
      "Thou art to live by thee: and the second Aufidius I ragged requires\n",
      "For never thought and charity thee quite:\n",
      "Yourafening, why learns, while a Roman, being\n",
      "lab, riseio; can departing of hisand have swallow, having nothing of war\n",
      "With most tongue remains and due: and your place\n",
      "Even in your blockMeth cast him all his eyes as true, they'll perfect,\n",
      "The stock graft,\n",
      "And with the Rosaline disgraced of the two mirrors;'I saw you make them still\n",
      "Our soul, doubtless\n",
      "Set heigh\n",
      "HASTINGS:\n",
      "Nothing the tavern, my lord?\n",
      "\n",
      "Laugh wars must be upon, fortune comes the morning, here brake,\n",
      "Shall witness, in faith.\n",
      "\n",
      "GLOUCESTER:\n",
      "'\n",
      "The widow is grown the way, killanth disgrace discourse's deep traged\n",
      "---------------\n",
      "Elapsed time: 22.050087690353394\n",
      "\n",
      "As the man walked down the stairs,  do that did.\n",
      "\n",
      "SorrowBA ta all?\n",
      "ANGELO:\n",
      "Call's eyes to this afternoon,\n",
      "TRANUS:\n",
      "Who fair hundred, but seldom that you talk we have been no more:\n",
      "Which I disbench.\n",
      "\n",
      "BRUTUS:\n",
      "I lay to earn.\n",
      "\n",
      "EXeseech say you come with this? Where to London!\n",
      "O:\n",
      "Here, hath not afflict: say, good\n",
      "And wounds that banish'd?\n",
      "Why. Do sea, since, will go see how fares thy breath\n",
      "That runaway do take heed the trial, which shall she took his life have all the honour,\n",
      "My lord, I see to him four tonguetyember,\n",
      "I let the women fellow, are manifest-madely as it. Well, and all'st pays for death;\n",
      "For I halt for the foe, proudle.\n",
      "\n",
      "My lady's frown you gone!\n",
      "Clown:\n",
      "Come your suit;\n",
      "Mist swift, by the Tower, I come. Say Grum!\n",
      "\n",
      "First Senator:\n",
      "I tell thy battle, but title?\n",
      "Ky answer, I misc, what hath abroach; battles incorporate fortune lives\n",
      "No, Signior Hortensioly fittingators nor man,\n",
      "The evil mine to't?\n",
      "GLOUCESTER:\n",
      "A, wastio and let me?\n",
      "Come?\n",
      "\n",
      "CLIFFORD:\n",
      "Mytis a week about thee,\n",
      "Or else is sick oracle, that prol makes not see\n",
      "To find him, hollowant gentleman to Delphos!\n",
      "When I could I had spoke. Comm the sun! come, ladies!\n",
      "\n",
      "Both:\n",
      "I will carry; O; for his house:\n",
      "He indeed\n",
      "Go get me soon'd up by along I have broken truth\n",
      "For she not, that you that I see\n",
      "Of what you.\n",
      "DUKE VINCENTIO: there you may he unto my voice,\n",
      "At Clarence,\n",
      "KING RICHARD III:\n",
      "A thief, mayst thou hast alive, what'st I know it.\n",
      "IET:\n",
      "Deitions; and out the husband,--this,\n",
      "As chance day prolongasing, what wail to't me; divine\n",
      "For both be second news is way which me yourself hither to both!\n",
      "\n",
      "The which none, saw these such imprisonment doth\n",
      "For our antic they not hide time; for all ages smack cool members;\n",
      "To whom it is come in arms then, but grief\n",
      "GARET: speaking friends for a\n",
      "A liege\n",
      "The rage deaf days King Edward's wife. Spirits it was rearve diet for he may wink\n",
      "Of the Tower,\n",
      "If we devise excuses is a manched to Romans\n",
      "Having me what you soever\n",
      "As bright, sistereming semblanceinius with this change often\n",
      "Which often that the sweat farewell,\n",
      "ates:\n",
      "No forth out of a virtuous swords, cursingadise\n",
      "Hadst souls to unanks, my lord, restrainings,\n",
      "Can this eyes; and have a mockery:\n",
      "Where is your majesty I must be open.\n",
      "\n",
      "ISABELLA:\n",
      "Go to you call'd you learn.\n",
      "\n",
      "GLOUCESTER:\n",
      "Uncle and love, that\n",
      "My life can make your best beloved:\n",
      "Such hideous her honourless, but we will go;\n",
      "Fall of certain text virtue after it is full unfful\n",
      "Anon them?\n",
      "Well in the thick.\n",
      "RIVERS:\n",
      "Fie 'music thee a it was a little kiss me her women,\n",
      "confession is scarce guess unto the king? why,\n",
      "DORSET: what of them, but so too; believe\n",
      "A husband and put about what nature?\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "That I had gone, that ret;\n",
      "But whether cut easier death, my lord;\n",
      "Nor excellent love, but by our gentle despair, which, this discoveryfully, six itself.\n",
      "Shall amaz become let you:\n",
      "The manner it would do bite not thunder,\n",
      "Are bloody infant, for mocking upon my brother,\n",
      "For thou had forged? why to churchyard proclaim upon hate,\n",
      "Whose how to flax and beggarithmetic than evil my life.\n",
      "\n",
      "DUKE OF YORK:\n",
      "And let them go along, speak no person: he did,\n",
      "This means shall do them, after, yet she you woo and shepherds-day,\n",
      "That you thank you speak's the lamb Hastings's daughter\n",
      "That now wert'd that have met yourself on the sun in a slave.\n",
      "\n",
      "GLOUCESTER:\n",
      "Then did infer comes his son; but I shall\n",
      "I am hungry cannib, raying; whom I repair brands to make all their office\n",
      "---------------\n",
      "Elapsed time: 22.41266441345215\n",
      "\n",
      "As the man walked down the stairs,  satisfy, wert.\n",
      "\n",
      "MARCIUS:\n",
      "ancing sure their hearts bold, let it comes,\n",
      "And bold flood from this presence world--\n",
      "Manifesto that nothing, madam,\n",
      "That may formally, Benvolio a dec acquaint.\n",
      "\n",
      "CLARENCE:\n",
      "Lay of not stir,\n",
      "To comfort-maid:\n",
      "Touch elsewhere the heavens directing lives then another day, the king cannot tell this dangerous?\n",
      "\n",
      "DERBY:\n",
      "As herbs a royal day!\n",
      "\n",
      "JULI gave's sun.\n",
      "LADY ANNE:\n",
      "'Tis the crows, one of the time's length;\n",
      "This cannot life.\n",
      "\n",
      "\n",
      "PARISABETH:\n",
      "Vill this business'd by hands;\n",
      "Than fool him:\n",
      "Why, Edward shall shake me; I make my country's strength:\n",
      "For pale that do your predecessors thou hast with a\n",
      "This purpose is as they 'What to my sin.\n",
      "\n",
      "First Servingman:\n",
      "First Servingman:\n",
      "There wreck saw the poor to me,\n",
      "And Warwick, we eat:\n",
      "Well, I see no more poor letter, yet fled.\n",
      "\n",
      "GLOUCESTER:\n",
      "It is the book that often still.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Not one with the young.\n",
      "\n",
      "Servant:\n",
      "I will keep.\n",
      "\n",
      "COMINCE EDWARD IV:\n",
      "Sweet some written, andueless man, young!\n",
      "CAPULETis made of good report,\n",
      "And leave, by the lord: if you are full died,\n",
      "As far as thou tell youman!\n",
      "\n",
      "GLOUCESTER:\n",
      "O:\n",
      "My lord, you talk's the tidings's fitness:\n",
      "This is worldlyness divorce and with the city;\n",
      "Is she pricks I have for himself?\n",
      "\n",
      "First Servingman, a duke; and blood\n",
      "In my forest army by taste grief.\n",
      "\n",
      "STor;\n",
      "Draw:\n",
      "'Tisement a forward duke for your pleasure.\n",
      "\n",
      "First Citizen:\n",
      "NotREL and smiles says into her employ.\n",
      "\n",
      "\n",
      "SAMPSON:\n",
      "The loss of that is frankling?\n",
      "\n",
      "LARTI want me here, my promise, Caius in the\n",
      "And now mistrustusedim: such a hopeful condemned?\n",
      "To the maid of this place.\n",
      "\n",
      ";\n",
      "It is nothingorous with Libya:\n",
      "I would his much not not noted of justice.\n",
      "\n",
      "this.\n",
      "First Servingman:\n",
      "I thank you shall I see how we must Five.\n",
      "\n",
      "FIDIUS:\n",
      "I will, ever came. Pray, go.\n",
      "\n",
      "\n",
      "VOLUMIO:\n",
      "What is great your good provoke\n",
      "Thus to give him! but heaven, wives are gone. Where are\n",
      "\n",
      "No, hated stays thus for I do\n",
      "Unert thy deeds is born have but that I am I do not without characters,\n",
      "re it.\n",
      "Why should expect all duty.\n",
      "our' the lord.\n",
      "QUE:\n",
      "Deserves.\n",
      "PETER:\n",
      "I say weakness it right of the self, title, why, all nic:\n",
      "In peace sure his wife, with Paris the north\n",
      "balt it not change and blunt:\n",
      "That he glazed to thy crown,\n",
      "myic wishing: let him with his death,\n",
      "Being were ground!\n",
      "They will well.\n",
      "\n",
      "GLOUCESTER:\n",
      "I shall be poor boy the city, and sovereignty should be their anchor. This;\n",
      "Thus know, at the officers thee nobly tree set upon one day?\n",
      "\n",
      "LUCIO:\n",
      "What were say that our counsel,\n",
      "Some Henry stands thee that ever. Letucy wid of breath,\n",
      "I shall turn of Edward found'd with the sun.\n",
      "\n",
      "\n",
      "Second Messenger:\n",
      "My life's death too much licence. What.\n",
      "\n",
      "BRUTUS:\n",
      "\n",
      "Messenger: say, with wild hurry between is,\n",
      "My lord: what, O,\n",
      "I'll make when the city the soul\n",
      "To speak; and 'love. Do, look'd for I'll go along,\n",
      "Th'd a very news now, he ruff;\n",
      "That he walks upon him! talk in her privately\n",
      "My great thy drybeat enough here comes which I must make all\n",
      "Fetch you are too and I beseech you;\n",
      "Shall, whose shade.\n",
      "To make brother's a ladderments an ease,\n",
      "When a vineyard where we are fled I know but lean,\n",
      "My news abroad shall be strength'd by Nature:\n",
      "But all this is Lordends? let him\n",
      "\n",
      "Frederick at stake am Pilven Richard that I know's.\n",
      "Fench that the exchange\n",
      "GREMIO: learn:--I meet and here with all mischanceate,\n",
      "\n",
      "---------------\n",
      "Elapsed time: 22.23010516166687\n",
      "\n",
      "As the man walked down the stairs,  of it.\n",
      "\n",
      "MENENVOLUMNIA:\n",
      "Proceedil things.\n",
      "\n",
      "First Servingman, how call they never or any undertaking:\n",
      "Where is a heavy sep in good or my husband and her,\n",
      "With the monarch a hall?\n",
      "In every minute content; and agony the old fill punishy man.\n",
      "\n",
      "CLARENCE:\n",
      "Bring forth this noble lord, beseech you all!\n",
      "\n",
      "KING RICHARDINAL:\n",
      "Good but good friend, my foe change his behold; where it,\n",
      "Will it beque the rascal:\n",
      "You haveTake heed in thee and no offence.\n",
      "\n",
      "LEONTESCATESBY:\n",
      "But that you offend, every otherote:\n",
      "constom light to m!\n",
      "We'll give in me, or my father,\n",
      "We see:\n",
      "She is come: peace to that valiantity.\n",
      "\n",
      "BRUTUS:\n",
      "Welcome, that shall stop thou run; it.\n",
      "\n",
      "KING EDWARD:\n",
      "My lord, rather but the fall out:\n",
      "Small, he loves is just censures that you say you.\n",
      "I'll keep them; which amorous frown;\n",
      "Upon on the deed well assured now,\n",
      "TYRUTUS:\n",
      "Clown: you that interrupts range deaths\n",
      "Behold for my father fright my descent: there comes in to all betw,\n",
      "And your daughter the blood that now I shall your holy by the\n",
      "Men time\n",
      "I prancing the earth, nor granted and fall that he did pass'd\n",
      "Which that ever know you and Derby.\n",
      "\n",
      "\n",
      "MENENI'll pay anyassat\n",
      "NIA: he is the news, turn you have burst thou hast foretell it of his wrink,\n",
      "your hours thinks of large him,\n",
      "The matter will we shall come that our household done your\n",
      "Your children. At: for his thought:\n",
      "And fa, now!\n",
      "\n",
      "FLORSON from you all, what, but I will you?\n",
      "\n",
      "PERDITAainted to my lords;\n",
      "I know the battle might what, to them\n",
      "Of a plain looks of a traitor\n",
      "Of his heart most sufficient gentlemen deserves,\n",
      "considered, Prince, a word fair Caesarting apt to thither,\n",
      "Wars vouchsafe Isabel, for sweet heart I\n",
      "Which now again after beseechres uncle fellow of suspicion of better,\n",
      "Which ever,\n",
      "How to thy emb of you when he be past day,\n",
      "But so old suitor between a brokenling,\n",
      "And therefore peace to my death till we there.\n",
      "\n",
      "MENENI thought you pass; and Lo'er.\n",
      "\n",
      "First Musician:\n",
      "HERMable sons his own bookes and his noble\n",
      "A wings, I\n",
      "In shape and Christian weeds: what I'er issueded to the\n",
      "OKE VINCENTIO:\n",
      "Soers him,\n",
      "To the Dukeful face, fair\n",
      "Are true soul hath make their sav continue Claudio did hast that they will come to sinners\n",
      "That jocundiscovered'd with a Christian Rutland.\n",
      "On your channel--there there's death to hate,\n",
      "We'll strive\n",
      "and it, you are stout lie, thank you\n",
      "des it for our course, that\n",
      "Than Hercules, it come to join her marriage's malignant,\n",
      "hon to see me in such as well your brother.\n",
      "\n",
      "First Watchman should have more mild boxes!\n",
      "\n",
      "Lufidius must end.\n",
      "\n",
      "LUCIO:\n",
      "Thanio are to nature with me, good right!\n",
      "\n",
      "\n",
      "A purpose have fought the parishling?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "For a mystery root, here.\n",
      "owards, to the day;\n",
      "The rage back\n",
      "To let'strees! 'tis not,\n",
      "What news?\n",
      "\n",
      "HERMeth better far off, neither claim the phoenix\n",
      "controvers\n",
      "Murder smoking reverence a very glories, and leaves what vile principal and 'T:\n",
      "\n",
      "But how, will to head\n",
      "To be.\n",
      "\n",
      "ROMEO:\n",
      "Well, till thou most red him from\n",
      "What is twelve at the victory\n",
      "With the like thehee--Godre.\n",
      "\n",
      "BRUTUS:\n",
      "FRIARET:\n",
      "Within take you fall forth;\n",
      "Master, that which added degree'd against this brave accompany them,\n",
      "For thy riches? Old of you both are fast, his grace by the\n",
      "And now. But first:\n",
      "Were, thou'st thy soul.\n",
      "\n",
      "GLOUCESTER:\n",
      "Is tedious stride still and did him for your request.\n",
      "HASTINGS:\n",
      "SICINI promised\n",
      "They will walk you well met, sir, be no less in being entreat a\n",
      "will by God disvalued alive to his father Tybalt-groundts\n",
      "\n",
      "---------------\n",
      "Elapsed time: 22.374009370803833\n",
      "\n",
      "As the man walked down the stairs, pt hath eat imped you men's time to leave my rest,\n",
      "And face iteth inform:\n",
      "Come, hath offended home again but very well.\n",
      "\n",
      "PAULI shall be might my Grey, God 'long.\n",
      "ARCH, far to ease it me with you\n",
      "FLOR John's sentenced may talked frown of kin of Camillo'd your prince:\n",
      "What; if elder,. What, good\n",
      "IET:\n",
      "Do the recorder that thou drow him, out.\n",
      "\n",
      "LARTI had I will sc, my body.\n",
      "\n",
      "First Citizen:\n",
      "What is slain, what is't like summerry;\n",
      "And couple is stale! why to the queen, good my chafed.\n",
      "Or can but weep held him on the doth I little but which of York\n",
      "Yet a maid with you shall be thus abide: say!\n",
      "The same, and all. I, master-ES:\n",
      "There our love's love's wife of the good than vows\n",
      "prop no stocks like your conference,\n",
      "This is gone: our brother is man and found\n",
      "Witness our hands the court's ghost of England. Yet him,\n",
      "\n",
      "HASTINGS:\n",
      "Tis very o' this humour that's man my very gross\n",
      "A rhy our solemn hy from the worst of courteous late from his.\n",
      "\n",
      "LADYORK:\n",
      "CESCESTER:\n",
      "Her sweet bubbleemen shookarine own science of doom there,\n",
      "What noise-t she may be no more.\n",
      "\n",
      "ROMEO:\n",
      "Is altogether man.' You banishedoused!\n",
      "\n",
      "MENENI?\n",
      "KING EDWARD IV:\n",
      "Prep strength, that sends, he's by that should\n",
      "We'll have your answer him.\n",
      "HENI may be alligator give by her match!\n",
      "\n",
      "NORTHUMIO:\n",
      "Be forget, and aptly, mighty to the noise of misdello: he each which is grownbl'd\n",
      "Her char our noble'Tis cup was Ag be the strangers\n",
      "A gentler,\n",
      "PRINCE EDWARD: he be revenged to the book.\n",
      "\n",
      "More torches him think's course, and flexible him, and\n",
      "me me see you to exp among,\n",
      "And doth aim cannot do:\n",
      "Which thus bold, I purpose a grimined pluck?\n",
      "\n",
      "QUEENVOLUMERRIVERS:\n",
      "The revenue fair heart's my son,\n",
      "But\n",
      "Law seven off a hand!\n",
      "\n",
      "SICINCE EDWARD IV:\n",
      "A persecut-he are behold best pays swallow exiledy day;\n",
      "Othou?\n",
      "And the news?\n",
      "\n",
      "GLOUCESTER:\n",
      "And cruel that heaven dreams enjoy him, Sirz ado was coming\n",
      "A vessel have.\n",
      "SICINCE EDWARD:\n",
      "Hold come, what means! why look the like a poor gentleman.\n",
      "\n",
      "COMINI had meant\n",
      "MARIANAufidius, and by his hands the greater victory.\n",
      "\n",
      "That he done, not yet, if their own fortune had not.\n",
      "\n",
      "\n",
      "HENIOLYCUS:\n",
      "HENESTER: yet, is maimurousry\n",
      "Be blamed here, spare is thy Juliet-mi and would never ever fault,\n",
      "Which myself and I hope is fullel run,\n",
      "That would not saint care and paper;\n",
      "Thy thy name, we fear\n",
      "Threeas to flow;\n",
      "And very well served her good will be best brother;\n",
      "It are bothitied for them.\n",
      "\n",
      "NORTHUMIO:\n",
      "Hadst be calm.\n",
      "I saw him, my gracious lord, your book degree you, my guiltyeth he would have known\n",
      "For this liege, those here grieves.\n",
      "PERDITA:\n",
      "But by Saint George more that his worth.\n",
      "\n",
      "CORIUS:\n",
      "The near-bed sc snow only that hot your own behalf the wars\n",
      "Is it will have:\n",
      "Mercyposed as fair comes to Mantua of my king,\n",
      "Which must everlast but see in my beating.\n",
      "HERMethinks, meaninghips.\n",
      "Right:\n",
      "Third Servingman:\n",
      "A whining trees:\n",
      "Why, my lord?\n",
      "\n",
      "\n",
      "Second Servingman, that they wouldst be it;--God'I? and that weeps life\n",
      "\n",
      "CAPULET:\n",
      "Do a glorious eyes that might have we friends; revenged so to think you wherein: Jupiter,\n",
      "O, Leontes to doit\n",
      "That it is gone.\n",
      "\n",
      "BI, brother.\n",
      "KING RICHARD III:\n",
      "Is bound am too much my lord?\n",
      "Farewell; therefore, flattery slain, by save me.\n",
      "\n",
      "QUEENIUS:\n",
      "Grand me not even remains, by your father,\n",
      "Must thou know not know it blessed are at\n",
      "---------------\n",
      "Elapsed time: 22.459355354309082\n",
      "[22.050087690353394, 22.41266441345215, 22.23010516166687, 22.374009370803833, 22.459355354309082]\n",
      "22.305244398117065\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_4bit = quantizing(output_path=model_name[:-3] + '_q.pt', quantize='gptq.int4')\n",
    "model_4bit.to(device)\n",
    "\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "print(\"No meta.pkl found, assuming GPT-2 encodings...\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "decode = lambda l: enc.decode(l)\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "# run generation\n",
    "time_per_sample = []\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            start_time = time.time()\n",
    "            y = model_4bit.generate_parallel(x, max_new_tokens, temperature=temperature)\n",
    "            #print(y)\n",
    "            print(decode(y[0].tolist()))\n",
    "            end_time = time.time()\n",
    "            print('---------------')\n",
    "            duration = end_time - start_time\n",
    "            print(f\"Elapsed time: {duration}\")\n",
    "            time_per_sample.append(duration)\n",
    "print(time_per_sample)\n",
    "print(sum(time_per_sample) / len(time_per_sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MScThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
